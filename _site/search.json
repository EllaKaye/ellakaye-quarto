[
  {
    "objectID": "community.html#r-user-groups",
    "href": "community.html#r-user-groups",
    "title": "Ella Kaye",
    "section": "R User Groups",
    "text": "R User Groups\nThere are local R User Groups (RUGs), affiliated with the R Consortium, all around the world. These are usually in person and offer an excellent way to meet other R users nearby. They all have Meetup pages. There’s also a great Shiny app for exploring the groups:\n RUGs on meetup  RUGs Shiny app\nI am on the organising committee of the Warwick R User Group (WRUG), and was previously an organiser of the Oxford R User Group.\n WRUG meetup  WRUG website  WRUG Twitter  WRUG GitHub"
  },
  {
    "objectID": "community.html#rladies",
    "href": "community.html#rladies",
    "title": "Ella Kaye",
    "section": "RLadies",
    "text": "RLadies\nRLadies has been around for over 10 years, promoting gender diversity in the R community. It is a worldwide organisation run by a global team, with local chapters all over the world. They also have a directory where you can browse their list of speakers for conferences & events, or view profiles of R-Ladies located by country.\n global website  local meetups  RLadies Shiny app  directory"
  },
  {
    "objectID": "community.html#rainbowr",
    "href": "community.html#rainbowr",
    "title": "Ella Kaye",
    "section": "rainbowR",
    "text": "rainbowR\nrainbowR’s mission is to support, promote and connect LGBTQ+ people in the R community and to and spread awareness of LGBTQ+ issues through data-driven activism. I am a co-founder and co-organiser of the group.\n website  join slack  slack group  Twitter  GitHub"
  },
  {
    "objectID": "community.html#r-forwards",
    "href": "community.html#r-forwards",
    "title": "Ella Kaye",
    "section": "R Forwards",
    "text": "R Forwards\nR Forwards is an R Foundation taskforce that leads the R community forwards in widening the participation of women and other under-represented groups. They also oversee the useR! conferences. I am a co-lead of the communities team. There’s more info on the website, though it’s rather out of date. The Twitter account is active.\n website  Twitter"
  },
  {
    "objectID": "community.html#data-science-data-visualisation-and-tidytuesday",
    "href": "community.html#data-science-data-visualisation-and-tidytuesday",
    "title": "Ella Kaye",
    "section": "Data science, data visualisation and #TidyTuesday",
    "text": "Data science, data visualisation and #TidyTuesday\nR for Data Science (R4DS) is a very friendly online learning community with an active slack group. It is a community of R users at all levels, working and learning together. There are learners and mentors and office hours, but everyone helps each other.\n website  Twitter\nR for Data Science also runs the hugely popular #TidyTuesday initiative, a weekly data project aimed at the R ecosystem. Every week they post from the R4DS account above, a raw dataset a chart or article related to that dataset, and ask you to explore and visualise the data, then share the visualisation and the code on Twitter with the hashtag #TIdyTuesday. All the datasets and participating guides are on GitHub.\n #TidyTuesday  GitHub\nI am an extremely infrequent contributor to #TidyTuesday. My contributions are on my GitHub.\n My TidyTuesday contributions"
  },
  {
    "objectID": "community.html#data-science-by-design",
    "href": "community.html#data-science-by-design",
    "title": "Ella Kaye",
    "section": "Data Science by Design",
    "text": "Data Science by Design\nData Science by Design (DSxD) celebrates creativity in data science and developing a more open, ethical, and inclusive future for data work. They run small conferences and an active slack group. They publish anthologies, both in print and online, collecting of work by data designers, scientists, and artists, with each issue on a different theme. I was honoured to be included in the first volume, with an article on {distilltools}.\n website  Twitter  book"
  },
  {
    "objectID": "community.html#twitter",
    "href": "community.html#twitter",
    "title": "Ella Kaye",
    "section": "Twitter",
    "text": "Twitter\nYou’ll have seen above links to various groups on Twitter. To follow and engage with the R community on twitter more broadly, the #rstats hashtag is the best place to start.\n #rstats"
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Ella Kaye",
    "section": "",
    "text": "I’d love to hear from you!\nYou can leave a note about any of my posts, talks or packages using the comment box at the bottom of each page.\nYou can find me on elsewhere online:\n\n\n\n Twitter  GitHub\n\n\n\nOr, you can drop me an e-mail at hello @ ellakaye.co.uk"
  },
  {
    "objectID": "posts/2021-05-08_welcome-distill/index.html",
    "href": "posts/2021-05-08_welcome-distill/index.html",
    "title": "Welcome to my {distill} website!",
    "section": "",
    "text": "Hello, and welcome to my new site, built using the {distill} package. Here’s why I switched from {blogdown}, and the resources and inspirations that helped me in the process."
  },
  {
    "objectID": "posts/2021-05-08_welcome-distill/index.html#why-distill",
    "href": "posts/2021-05-08_welcome-distill/index.html#why-distill",
    "title": "Welcome to my {distill} website!",
    "section": "Why {distill}?",
    "text": "Why {distill}?\nAs the documentation says, {distill} for R Markdown is a web publishing format optimised for scientific and technical communication. Recent updates to the package, particularly the ability to customise the theme through the create_theme() function, have made it a really appealing choice for those wanting a personalised website based only on R Markdown. The fact that {distill} is made just in R Markdown is a big win for those not wanting to go down (or, like me, looking to get away from), the Hugo route. I’d had a Hugo Academic website for four years, built on {blogdown}, and had been stung a number of times by it breaking after updates to Hugo and Hugo Academic. Last year, I switched to {hugodown}, and that helped, but I had some serious FOMO following that shift after the release of {blogdown} v1.0 a few months later, with all its handy check functions. By then, anyway, I was also displeased with the shift from Hugo Academic to Wowchemy, and getting a little bored of that theme anyway. I had also started seeing more and more {distill} sites pop up from those I admire in the RStats community. I looked into it and and I loved the simplicity of it, both in looks and in management. No more impenetrable file structures! No more not being sure quite why my website is working/looking as it does! Attending Alison Hill’s incredible ‘Crafting Kind Tools’ talk, in which she described the care put into making the {distill} user experience an enjoyable one, was the last push I needed to start my website again (though, to be fair, that talk also described similar care put into the latest release of {blogdown}).\nI’m finding working with {distill} to be an absolute joy!"
  },
  {
    "objectID": "posts/2021-05-08_welcome-distill/index.html#resources",
    "href": "posts/2021-05-08_welcome-distill/index.html#resources",
    "title": "Welcome to my {distill} website!",
    "section": "Resources",
    "text": "Resources\nThis post is not a guide on how to get a {distill} site up an running. There are already great resources for that. In particular, here are the resources I found helpful.\n\nThe basics\n\nThe blogpost from RStudio on (Re-)introducting Distill for R Markdown is a great place to start.\nFor getting up and running, the official {distill} documentation is excellent (and also a {distill} website).\nWhilst we’re on resources from the RStudio team, it’s worth remembering that because {distill} is built on {rmarkdown}, recent developments to that package, such as the ability to style a site with {sass} 1, and developments in {knitr}, such as the ability to easily add alt-text to images, follow through to {distill} too.\nThere’s a great building a blog with distill post from Tom Mock\nAnd one on building a {distill} website from Lisa Lendway\n\n\n\nNext steps\n\nThe {postcards} package from Sean Kross makes it incredibly easy to create simple, stylish, landing pages, and they make great home pages for {distill} sites. Alison Hill has a walk-through on how to set this up: M-F-E-O: postcards + distill\nTom Mock has another excellent {distill} post on including and meta tagging extra content in a distill blog, useful for if/when you want your site to contain content other than distill_articles\nWhilst the create_post() function in {distill} is a great way to get started on a blog post, Eric Ekholm shows how he developed a function wrapped around it to personalise the {distill} template\nFor styling content, John Helveston shows how to customise {distill} with {htmltools} and CSS.\nIf you want to allow readers to comment on your posts, then follow this guide from Vebash Naidoo on how to enable utterances with {distill}"
  },
  {
    "objectID": "posts/2021-05-08_welcome-distill/index.html#inspirationscode",
    "href": "posts/2021-05-08_welcome-distill/index.html#inspirationscode",
    "title": "Welcome to my {distill} website!",
    "section": "Inspirations/Code",
    "text": "Inspirations/Code\nI’m extremely grateful to the authors of the above posts for taking the time to write up what they’ve developed and what they know/have learnt to do, therefore making it easy for others to apply. I guess that’s what blogs are for! But I’ve also learnt a lot from finding sites that I simply like the look of, or have cool features, and looking at the source code on GitHub and adapting it for my own site. Here are some sites that I’ve drawn on for inspiration and code2:\n\n\n\n\nJohn Helveston\n\n site  source\nI particularly like his icon_link buttons (as demonstrated just above), and the second collection for talks. John tells me he is turn took inspiration for this from Emi Tanaka’s site.\n\nIjeamaka Anyene\n\n site  source\nIjeamaka has a really cool projects page, where she’s created a card for each project, which I’ve implemented on my site.\n\nTom Mock\n\n site  source\nCome for the minimalist, stylish design, stay for the fantastic blog content, not just on {distill}, but also on {gt}, R Markdown, #TidyTuesday and much more besides."
  },
  {
    "objectID": "posts/2021-05-08_welcome-distill/index.html#finding-out-more",
    "href": "posts/2021-05-08_welcome-distill/index.html#finding-out-more",
    "title": "Welcome to my {distill} website!",
    "section": "Finding out more",
    "text": "Finding out more\nThe above just scratches the surface. There are many more great sites built on {distill} out there, and lots more ways to customise them. Below are some good ways to find out more.\n\nThe distillery\nThe distillery is a {distill} blog about building {distill} blogs and websites. As the site’s GitHub README states:\n\nThis site was built for the community of distill users to find ways to build and customize their sites and to inspire one another. If you have a distill website or blog, we would love to have it included in the distillery showcase! Have a post about ways to customize or add new features to your blog? We would love to have it included on the distillery tips & tricks page!\n\nThe showcase is a great place to browse sites for inspiration and the tips and tricks page has loads of great resources (many of which I want to implement on my site in the future, for example Jannick Buhr’s post on making a dark mode for your {distill} site).\n\n\nTwitter\nThere are a number of folk who tweet about {distill} (alongside other #rstats content). I’ve seen useful tweets from Shannon Pileggi @PipingHotData, Lisa Lendway @lisalendway and John Helveston @JohnHelveston. And it pretty much goes without saying that anyone with an interest in {distill} should be following its authors (and general R Markdown gurus), Alison Hill @apreshill, Christophe Dervieux @chrisderv, Rich Iannone @riannone and Yihui Xie @xieyihui (note that the author and original creator of {distill} is JJ Allaire - he does have a twitter account but doesn’t seem to use it)."
  },
  {
    "objectID": "posts/2021-05-08_welcome-distill/index.html#a-sneak-peek-at-distilltools",
    "href": "posts/2021-05-08_welcome-distill/index.html#a-sneak-peek-at-distilltools",
    "title": "Welcome to my {distill} website!",
    "section": "A sneak-peek at {distilltools}",
    "text": "A sneak-peek at {distilltools}\nInspiried by the above-mentioned posts from John Helveston and Eric Ekholm, I’ve started working on a package, {distilltools}, a collection of tools to support the creation and styling of content on websites created using {distill}.\n site  source\nIt is in the very early stages of development. I am actively seeking contributions - both ideas and code - to help build the package to be broadly useful to a wide variety of {distill} users. The idea is for the package to become a curated, collaborative, community-driven project. Please see the contributing guide for more details on how to get involved. In terms of relationship between packages, I hope in time that {distilltools} can be for {distill} something like what {xaringanExtra} and {xaringanthemer} are for {xaringan}. Some of what I have in mind may sit better within the distill package itself, and I am in touch with the {distill} team about that.\nAt the time of writing, there are just three functions:\n\nicon_link: creates the html for a link button with icon and text (as seen above). Output of icon_link will need styling via the icon-link class to make it look like a button.\ncreate_talk(): a wrapper around distill::create_post() that creates a post in the talk directory and includes buttons (made with icon-link()) for slides (both web and pdf), material, video and project. These can easily be edited in the resulting .Rmd file.\ncreate_post_from_template(): this function operates almost identically to distill::create_post() except for the addition of a path argument, which allows the user to pass in a path to an .Rmd file that can be used as a template for the post. (Note that this function is likely going to be pulled into the {distill} package and hence be depreciated here.)\n\nExpect to hear much more from me, both on this blog and twitter, about {distilltools} in the near future."
  },
  {
    "objectID": "posts/2021-05-08_welcome-distill/index.html#last-updated",
    "href": "posts/2021-05-08_welcome-distill/index.html#last-updated",
    "title": "Welcome to my {distill} website!",
    "section": "Last updated",
    "text": "Last updated\n\n2022-11-11 21:33:56 GMT"
  },
  {
    "objectID": "posts/2021-05-08_welcome-distill/index.html#details",
    "href": "posts/2021-05-08_welcome-distill/index.html#details",
    "title": "Welcome to my {distill} website!",
    "section": "Details",
    "text": "Details\n\nsource code, R environment"
  },
  {
    "objectID": "posts/2020-12-09_advent-of-code-2020/index.html",
    "href": "posts/2020-12-09_advent-of-code-2020/index.html",
    "title": "Advent of Code 2020",
    "section": "",
    "text": "Advent of Code is a series of small programming challenges, released daily throughout December in the run-up to Christmas. Part 1 of the challenge is given first. On its successful completion, Part 2 is revealed. The challenges are designed to be solved in any programming language. I will be using R.\nThere will no doubt be a wide variety of ways to solve these problems. I’m going to go with the first thing I think of that gets the right answer. In most cases, I expect that there will be more concise and efficient solutions. Most of the time I’m working in R, it’s within the tidyverse, so I imagine that framework will feature heavily below.\nEach participant gets different input data, so my numerical solutions may be different from others. If you’re not signed up for Advent of Code yourself, but want to follow along with my data, you can download it at from the data links at the beginning of each day’s section. The links in the day section headers take you to challenge on the Advent of Code page."
  },
  {
    "objectID": "posts/2020-12-09_advent-of-code-2020/index.html#day-1-report-repair",
    "href": "posts/2020-12-09_advent-of-code-2020/index.html#day-1-report-repair",
    "title": "Advent of Code 2020",
    "section": "Day 1: Report Repair",
    "text": "Day 1: Report Repair\n\n\n\nMy day 1 data\n\nPart 1: Two numbers\nThe challenge is to find two numbers from a list that sum to 2020, then to report their product.\nexpand.grid() creates a data frame from all combinations of the supplied vectors. Since the vectors are the same, each pair is duplicated. In this case the two numbers in the list that sum to 2020 are 704 and 1316, and we have one row with 704 as Var1 and one with 704 as Var2. slice(1) takes the first occurrence of the pair.\n\n\nToggle the code\nlibrary(dplyr)\n\nexpenses <- readLines(\"data/AoC_day1.txt\") %>%\n  as.numeric()\n\nexpand.grid(expenses, expenses) %>% \n  mutate(sum = Var1 + Var2) %>%\n  filter(sum == 2020) %>%\n  mutate(prod = Var1 * Var2) %>%\n  slice(1) %>%\n  pull(prod)\n\n\n[1] 926464\n\n\n\n\nPart 2: Three numbers\nThe follow-up challenge is the same but with three numbers. I went with essentially the same code but it’s notably slower. There are a lot of repeated calculations here: each triplet appears six times in the table.\n\n\nToggle the code\nexpand.grid(expenses, expenses, expenses) %>% \n  mutate(sum = Var1 + Var2 + Var3) %>%\n  filter(sum == 2020) %>%\n  mutate(prod = Var1 * Var2 * Var3) %>%\n  slice(1) %>%\n  pull(prod)\n\n\n[1] 65656536"
  },
  {
    "objectID": "posts/2020-12-09_advent-of-code-2020/index.html#day-2-password-philosophy",
    "href": "posts/2020-12-09_advent-of-code-2020/index.html#day-2-password-philosophy",
    "title": "Advent of Code 2020",
    "section": "Day 2: Password Philosophy",
    "text": "Day 2: Password Philosophy\nMy day 2 data\n\nPart 1: Number of letters\nWe need to find how many passwords are valid according to their policy. The policies and passwords are given as follows:\n1-3 a: abcde\n1-3 b: cdefg\n2-9 c: ccccccccc\nEach line gives the password policy and then the password. The password policy indicates the lowest and highest number of times a given letter must appear for the password to be valid. For example, 1-3 a means that the password must contain a at least 1 time and at most 3 times.\n\n\nToggle the code\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(stringr)\n\n\nFirst load the libraries we’ll need. We then read in the data and use tidyr functions to separate out the parts of the policy and the password, making sure to convert the columns to numeric as appropriate:\n\n\nToggle the code\npasswords <- readr::read_tsv(\"data/AoC_day2.txt\", col_names = FALSE) %>%\n  separate(X1, c(\"policy\", \"password\"), sep = \":\") %>%\n  separate(policy, c(\"count\", \"letter\"), sep = \" \") %>%\n  separate(count, c(\"min\", \"max\")) %>%\n  mutate(min = as.integer(min),\n         max = as.integer(max))\n\n\nNext, we use the stringr function str_count() to count how many times the given letter appears in the password, and conditional logic to check whether it is repeated within the specified number of times. Because TRUE has a numeric value of 1 and FALSE has a numeric value of 0, we can sum the resulting column to get a count of how many passwords are valid according to their policies.\n\n\nToggle the code\npasswords %>%\n  mutate(count = str_count(password, letter)) %>%\n  mutate(password_in_policy = if_else(count >= min & count <= max, TRUE, FALSE)) %>%\n  summarise(correct = sum(password_in_policy)) %>%\n  pull(correct)\n\n\n[1] 625\n\n\n\n\nPart 2: Position of letters\nNow the policy is interpreted differently. Each policy actually describes two positions in the password, where 1 means the first character, 2 means the second character, and so on. Exactly one of these positions must contain the given letter. How many are valid now?\nThere were a couple of gotchas here. When I used separate() in the previous part, I had inadvertently left a leading whitespace in front of the password, something that was messing up my indexing with str_sub. Using str_trim() first cleared that up. Also, we need exactly one of the positions to match. | is an inclusive or. We need xor() for exclusive or instead.\n\n\nToggle the code\npasswords %>%\n  mutate(password = str_trim(password)) %>%\n  mutate(pos1_letter = str_sub(password, min, min),\n         pos2_letter = str_sub(password, max, max)) %>%\n  mutate(match_one = xor(pos1_letter == letter, pos2_letter == letter)) %>%\n  summarise(correct = sum(match_one)) %>%\n  pull(correct) \n\n\n[1] 391"
  },
  {
    "objectID": "posts/2020-12-09_advent-of-code-2020/index.html#day-3-toboggan-trajectory",
    "href": "posts/2020-12-09_advent-of-code-2020/index.html#day-3-toboggan-trajectory",
    "title": "Advent of Code 2020",
    "section": "Day 3: Toboggan Trajectory",
    "text": "Day 3: Toboggan Trajectory\nMy day 3 data\n\nPart 1: Encountering trees\nStarting at the top left corner of the map, how many trees (“#”) do we encounter, going at a trajectory of 3 right and 1 down?\nFirst, read in the data and save it into a matrix. My method here feels really hack-y. I’m sure there must be a better approach.\n\n\nToggle the code\nlibrary(dplyr)\n\ntree_map <- readr::read_tsv(\"data/AoC_day3.txt\", col_names = FALSE)\n\nnum_col <- tree_map %>%\n  mutate(length = str_length(X1)) %>%\n  slice(1) %>%\n  pull(length)\n\ntree_vec <- tree_map %>%\n  mutate(X1 = strsplit(X1, split = character(0), fixed = TRUE)) %>%\n  pull(X1) %>%\n  unlist()\n\ntree_mat <- matrix(tree_vec, ncol = num_col, byrow = TRUE)\n\n\nNow work my way across and down the matrix, using the %% modulo operator to loop round where necessary. The -1 and +1 in the line ((y + right - 1) %% num_col) + 1 is a hack to get round the fact that, for num_col columns, the modulo runs from 0 to num_col - 1, but the column indexes for our matrix run from 1 to num_col.\n\n\nToggle the code\nright <- 3\ndown <- 1\n\nnum_rows <- nrow(tree_mat)\nnum_col <- ncol(tree_mat)\n\n# start counting trees encountered\ntrees <- 0\n\n# start square\nx <- 1\ny <- 1\n  \nwhile (x <= num_rows) {\n  \n  # cat(\"row: \", x, \"col: \", y, \"\\n\")\n  \n  if (tree_mat[x,y] == \"#\") trees <- trees + 1\n  \n  x <- x + down\n  y <- ((y + right - 1) %% num_col) + 1\n  \n}\n\ntrees\n\n\n[1] 299\n\n\n\n\nPart 2: Checking further slopes\nWe now need to check several other trajectories, and multiply together the number of trees we find, so we wrap the Part 1 code into a function.\n\n\nToggle the code\nslope_check <- function(tree_mat, right, down) {\n  \n  num_rows <- nrow(tree_mat)\n  num_col <- ncol(tree_mat)\n\n  # start counting trees encountered\n  trees <- 0\n\n  # start square\n  x <- 1\n  y <- 1\n  \n  while (x <= num_rows) {\n  \n    if (tree_mat[x,y] == \"#\") trees <- trees + 1\n  \n    x <- x + down\n    y <- ((y + right - 1) %% num_col) + 1\n  \n  }\n  trees\n}\n\nprod(slope_check(tree_mat, 1, 1),\n     slope_check(tree_mat, 3, 1),\n     slope_check(tree_mat, 5, 1),\n     slope_check(tree_mat, 7, 1),\n     slope_check(tree_mat, 1, 2))\n\n\n[1] 3621285278"
  },
  {
    "objectID": "posts/2020-12-09_advent-of-code-2020/index.html#day-4-passport-processing",
    "href": "posts/2020-12-09_advent-of-code-2020/index.html#day-4-passport-processing",
    "title": "Advent of Code 2020",
    "section": "Day 4: Passport Processing",
    "text": "Day 4: Passport Processing\n\n\n\nMy day 4 data\n\nPart 1: Complete passports\n\n\nToggle the code\nlibrary(dplyr)\nlibrary(tidyr)\n\n\nUsing readr::read_tsv() off the bat removes the blank lines, making it impossible to identify the different passports, but reading in the data via readLines() then converting as_tibble() preserves them, and then allows us to use tidyverse functions for the remaining tidying. cumsum() on a logical vectors takes advantage of FALSE having a numeric value of zero and TRUE having a numeric value of one.\n\n\nToggle the code\npassports <- readLines(\"data/AoC_day4.txt\") %>%\n  as_tibble() %>%\n  separate_rows(value, sep = \" \") %>%\n  mutate(new_passport = value == \"\") %>%\n  mutate(ID = cumsum(new_passport) + 1) %>%\n  filter(!new_passport) %>%\n  select(-new_passport) %>%\n  separate(value, c(\"key\", \"value\"), sep = \":\") %>%\n  relocate(ID)\n\n\nOur data is now in three columns, with ID, key and value, so now we need to find the number of passports with all seven fields once cid is excluded:\n\n\nToggle the code\npassports %>%\n  filter(key != \"cid\") %>%\n  count(ID) %>%\n  filter(n == 7) %>%\n  nrow()\n\n\n[1] 210\n\n\n\n\nPart 2: Valid passports\nNow we need to add data validation checks:\n\nbyr (Birth Year) - four digits; at least 1920 and at most 2002.\niyr (Issue Year) - four digits; at least 2010 and at most 2020.\neyr (Expiration Year) - four digits; at least 2020 and at most 2030.\nhgt (Height) - a number followed by either cm or in:\n\nIf cm, the number must be at least 150 and at most 193.\nIf in, the number must be at least 59 and at most 76.\n\nhcl (Hair Color) - a # followed by exactly six characters 0-9 or a-f.\necl (Eye Color) - exactly one of: amb blu brn gry grn hzl oth.\npid (Passport ID) - a nine-digit number, including leading zeroes.\ncid (Country ID) - ignored, missing or not.\n\nIgnoring the cid field, we narrow down on passports that at least have the right number of fields, and extract the number from the hgt column:\n\n\nToggle the code\ncomplete_passports <- passports %>%\n  filter(key != \"cid\") %>%\n  add_count(ID) %>%\n  filter(n == 7) %>%\n  select(-n) %>%\n  mutate(hgt_value = case_when(\n    key == \"hgt\" ~ readr::parse_number(value),\n    TRUE ~ NA_real_)) %>%\n  ungroup()\n\n\nThen we create a check column, which is TRUE when the value for each key meets the required conditions. Those with 7 TRUEs are valid. Note that with case_when() we’ve left the check column as NA when the condition is FALSE, requiring na.rm = TRUE in the call to sum(). We can get round that by adding a final line to the case_when() condition stating TRUE ~ FALSE. TRUE here is a catch-all for all remaining rows not covered by the conditions above, and then we set them to FALSE, but I find the line TRUE ~ FALSE unintuitive.\n\n\nToggle the code\ncomplete_passports %>%\n  mutate(check = case_when(\n    (key == \"byr\" & value >= 1920) & (key == \"byr\" & value <= 2002) ~ TRUE,\n    (key == \"iyr\" & value >= 2010) & (key == \"iyr\" & value <= 2020) ~ TRUE,\n    (key == \"eyr\" & value >= 2020) & (key == \"eyr\" & value <= 2030) ~ TRUE,\n    key == \"hgt\" & str_detect(value, \"cm\") & hgt_value >= 150 & hgt_value <= 193 ~ TRUE,\n    key == \"hgt\" & str_detect(value, \"in\") & hgt_value >= 59 & hgt_value <= 76 ~ TRUE,  \n    key == \"hcl\" & str_detect(value, \"^#[a-f0-9]{6}$\") ~ TRUE,\n    key == \"ecl\" & value %in% c(\"amb\", \"blu\", \"brn\", \"gry\", \"grn\", \"hzl\", \"oth\") ~ TRUE,\n    key == \"pid\" & str_detect(value, \"^[0-9]{9}$\") ~ TRUE\n  )) %>%\n  group_by(ID) %>%\n  summarise(check_all = sum(check, na.rm = TRUE)) %>%\n  filter(check_all == 7) %>%\n  nrow()\n\n\n[1] 131"
  },
  {
    "objectID": "posts/2020-12-09_advent-of-code-2020/index.html#day-5-binary-boarding",
    "href": "posts/2020-12-09_advent-of-code-2020/index.html#day-5-binary-boarding",
    "title": "Advent of Code 2020",
    "section": "Day 5: Binary Boarding",
    "text": "Day 5: Binary Boarding\nMy day 5 data\n\nPart 1: Finding all seat IDs\n\n\nToggle the code\nlibrary(dplyr)\nlibrary(stringr)\n\n\nThe code below sets starts by setting each row number to 127 and each column number to 7, the maximum they can be, then, working along the string, lowering the maximum (or leaving it as is) one letter at a time:\n\n\nToggle the code\nboarding <- readr::read_tsv(\"data/AoC_day5.txt\", col_names = FALSE) %>%\n  rename(binary = X1)\n\nseat_IDs <- boarding %>%\n  mutate(row = 127) %>%\n  mutate(col = 7) %>%\n  mutate(row = if_else(str_sub(binary, 1, 1) == \"F\", row - 64, row)) %>%\n  mutate(row = if_else(str_sub(binary, 2, 2) == \"F\", row - 32, row)) %>%\n  mutate(row = if_else(str_sub(binary, 3, 3) == \"F\", row - 16, row)) %>%\n  mutate(row = if_else(str_sub(binary, 4, 4) == \"F\", row - 8, row)) %>%\n  mutate(row = if_else(str_sub(binary, 5, 5) == \"F\", row - 4, row)) %>%\n  mutate(row = if_else(str_sub(binary, 6, 6) == \"F\", row - 2, row)) %>%\n  mutate(row = if_else(str_sub(binary, 7, 7) == \"F\", row - 1, row)) %>%\n  mutate(col = if_else(str_sub(binary, 8, 8) == \"L\", col - 4, col)) %>%\n  mutate(col = if_else(str_sub(binary, 9, 9) == \"L\", col - 2, col)) %>%  \n  mutate(col = if_else(str_sub(binary, 10, 10) == \"L\", col - 1, col)) %>%  \n  mutate(ID = row * 8 + col) \n\nseat_IDs %>%\n  summarise(max = max(ID)) %>%\n  pull(max)\n\n\n[1] 963\n\n\nOK, I know I said in the introduction to this post that I would go with the first solution I think of that gets the right answer, and the above does work, but I’m deeply unhappy with the code. There’s too much repetition, I don’t like the use of subtraction when diving by 2 feels more appropriate in a binary context, and it doesn’t feel like I’ve taken full advantage of the mathematical structure of the problem. So, on further reflection, I realise that the way that ID is defined is essentially turning a binary number into a decimal, where we get the binary number as a string by replacing “B” and “R” by “1” and L” and “F” by “0”. Then, I just found, there is a base R function strtoi() that takes a string of digits in a given base and converts it to a base 10 integer, just what we need:\n\n\nToggle the code\nseat_IDs <- boarding %>%\n  mutate(binary = str_replace_all(binary, \"L|F\", \"0\")) %>%\n  mutate(binary = str_replace_all(binary, \"B|R\", \"1\")) %>%\n  mutate(ID = strtoi(binary, base = 2)) %>%\n  arrange(desc(ID))\n\nseat_IDs %>%\n  slice(1) %>%\n  pull(ID)\n\n\n[1] 963\n\n\nThat’s better!\n\n\nPart 2: Finding my seat ID\nWe need to find the missing number, so we arrange the IDs in ascending order and look at the gap between each ID and the preceding one. In most cases, that should be one. Where we have a gap of 2, we must have skipped the integer below:\n\n\nToggle the code\nseat_IDs %>%\n  arrange(ID) %>%\n  mutate(diff = lag(ID)) %>%\n  mutate(gap = ID - diff) %>% \n  filter(gap == 2) %>%\n  summarise(my_seat = ID - 1) %>%\n  pull(my_seat)\n\n\n[1] 592"
  },
  {
    "objectID": "posts/2020-12-09_advent-of-code-2020/index.html#day-6-custom-customs",
    "href": "posts/2020-12-09_advent-of-code-2020/index.html#day-6-custom-customs",
    "title": "Advent of Code 2020",
    "section": "Day 6: Custom Customs",
    "text": "Day 6: Custom Customs\nMy day 6 data\n\nPart 1: Anyone answers\n\n\nToggle the code\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(stringr)\n\n\nWithin each group, we need to find the number of unique letters within each group. We read in and separate the data using the tricks learnt for Day 4, and take advantage of the rowwise() feature in dplyr 1.0.0.\n\n\nToggle the code\ncustoms_groups <- readLines(\"data/AoC_day6.txt\") %>%\n  as_tibble() %>%\n  mutate(new_group = value == \"\") %>%\n  mutate(group_ID = cumsum(new_group) + 1) %>%\n  filter(!new_group) %>%\n  select(-new_group) %>%\n  group_by(group_ID) \n\ncustoms_groups %>%\n  summarise(qs = str_c(value, collapse = \"\")) %>%\n  ungroup() %>%\n  mutate(qss = str_split(qs, \"\")) %>%\n  rowwise() %>%\n  mutate(qsu = list(unique(qss))) %>%\n  mutate(count = length(qsu)) %>%\n  ungroup() %>%\n  summarise(total = sum(count)) %>%\n  pull(total)\n\n\n[1] 6585\n\n\n\n\nPart 2: Everyone answers\nNow, instead of unique letters in a group, we need to find the number of letters which appear in all the answers for everyone in the same group. I first note how many people are in each group, then tabulate the number of occurrences of each letter in the group, then count (by summing a logical vector) the number of matches between occurrences of letter and the number in group. Finally, we sum across all groups.\n\n\nToggle the code\ncustoms_groups %>%  \n  add_count(group_ID, name = \"num_in_group\") %>%\n  group_by(group_ID, num_in_group) %>%\n  summarise(qs = str_c(value, collapse = \"\")) %>%\n  ungroup() %>%\n  mutate(qss = str_split(qs, \"\")) %>%\n  rowwise() %>%\n  mutate(letter_table = list(table(qss))) %>%\n  slice(1) %>%\n  mutate(in_common = sum(num_in_group == letter_table)) %>%\n  ungroup() %>%\n  summarise(total = sum(in_common)) %>%\n  pull(total)\n\n\n[1] 3276"
  },
  {
    "objectID": "posts/2020-12-09_advent-of-code-2020/index.html#day-7-handy-haverstocks",
    "href": "posts/2020-12-09_advent-of-code-2020/index.html#day-7-handy-haverstocks",
    "title": "Advent of Code 2020",
    "section": "Day 7: Handy Haverstocks",
    "text": "Day 7: Handy Haverstocks\nMy day 7 data\n\nPart 1: Number of colour bags\n\n\nToggle the code\nlibrary(tidyverse)\n\n\nWe have colour-coded bags that must contain a specific number of other colour-coded bags.\n\n\nToggle the code\nbags <- read_tsv(\"data/AoC_day7.txt\", col_names = FALSE)\n\nhead(bags)\n\n\n# A tibble: 6 × 1\n  X1                                                                            \n  <chr>                                                                         \n1 wavy bronze bags contain 5 striped gold bags, 5 light tomato bags.            \n2 drab indigo bags contain 4 pale bronze bags, 2 mirrored lavender bags.        \n3 pale olive bags contain 3 faded bronze bags, 5 wavy orange bags, 3 clear blac…\n4 faded white bags contain 5 vibrant violet bags, 4 light teal bags.            \n5 mirrored magenta bags contain 2 muted cyan bags, 3 vibrant crimson bags.      \n6 dull purple bags contain 1 striped fuchsia bag.                               \n\n\nOur first task is to parse the natural language and split the rules into one container/contains pair per line:\n\n\nToggle the code\nrules <- bags %>%\n  mutate(rule = row_number()) %>%\n  separate(X1, c(\"container\", \"contains\"), sep = \" bags contain \") %>%\n  separate_rows(contains, sep = \",\") %>%\n  mutate(contains = str_remove(contains, \"\\\\.\")) %>%\n  mutate(contains = str_remove(contains, \"bags|bag\")) %>%\n  #mutate(contains = str_replace(contains, \"no other\", \"0 other\")) %>%\n  extract(contains, c('number', 'contains'), \"(\\\\d+) (.+)\") %>%\n  filter(!is.na(number)) %>%\n  mutate(contains = str_trim(contains)) %>%\n  mutate(number = as.integer(number)) \n\n\nTo find all bags that con eventually contain our shiny gold bag, we first find the bags that can contain it directly. We then find the bags that can contain those bags and take the union of the two levels. We repeat, stopping when going up a level adds no further bags to the vector of bag colours already found. We then subtract 1, because we don’t want to count the original shiny gold bag.\n\n\nToggle the code\n# function to find all colours that contain a vector of other colours:\ncontains_colours <- function(colours) {\n  rules %>%\n    filter(contains %in% colours) %>%\n    distinct(container) %>%\n    pull(container)\n}\n\nbags <- \"shiny gold\"\nold_length <- length(bags)\nnew_length <- 0\n\n# keeping adding to the vector of bags, until no change\nwhile(old_length != new_length) {\n  old_length = length(bags)\n  bags <- base::union(bags, contains_colours(bags)) %>% unique()\n  new_length <- length(bags)\n  #cat(old_length, \", \", new_length, \"\\n\")\n}\n\nlength(bags) - 1\n\n\n[1] 274\n\n\n\n\nPart 2: Number of bags\nNow we need to discover the number of bags that a shiny gold bag must contain. I figured that lends itself to recursion, but struggled on the details. Hat tip to David Robinson for this solution. I’ve learnt a lot for myself by unpicking how it works.\n\n\nToggle the code\ncount_all_contained <- function(colour) {\n  \n  relevant_rules <- rules %>%\n    filter(container %in% colour)\n  \n  sum(relevant_rules$number * (1 + map_dbl(relevant_rules$contains, count_all_contained)))\n  \n}\n\ncount_all_contained(\"shiny gold\")\n\n\n[1] 158730"
  },
  {
    "objectID": "posts/2020-12-09_advent-of-code-2020/index.html#day-8-handheld-halting",
    "href": "posts/2020-12-09_advent-of-code-2020/index.html#day-8-handheld-halting",
    "title": "Advent of Code 2020",
    "section": "Day 8: Handheld Halting",
    "text": "Day 8: Handheld Halting\nMy day 8 data\n\nPart 1: Infinite Loop\nOur programme gets stuck in an infinite loop. As well as keeping track of the accumulator, we need to keep track of where we’ve visited, and stop when we visit the same instruction twice. We use a data.frame() rather than a tibble() as the former is easier to index into.\n\n\nToggle the code\ninstructions <- \n  read.table(\"data/AoC_day8.txt\", col.names = c(\"instruction\", \"value\"))\n\n\nWe start with a pretty straight-forward loop, noting that at most it can run for one more than the number of instructions in the programme until it hits an instruction it’s already visited. We update row number to visit next and the accumulator as appropriate.\n\n\nToggle the code\ninstructions$visited <- 0\n\nrow <- 1\naccumulator <- 0\n\nnum_rows <- nrow(instructions)\n\nfor (i in 1:(num_rows+1)) {\n\n  if (instructions[row, \"visited\"] != 0) break\n  \n  # +1 on number of times the row is visited\n  instructions[row, \"visited\"] <- instructions[row, \"visited\"] + 1\n\n  # case when the instruction is \"acc\"\n  if (instructions[row, \"instruction\"] == \"acc\") {\n    accumulator <- accumulator + instructions[row, \"value\"]\n    row <- row + 1\n  }\n  \n  # case when the instruction is \"jmp\"\n  else if (instructions[row, \"instruction\"] == \"jmp\") {\n    row <- row + instructions[row, \"value\"]\n  }\n\n  # case when the instruction is \"nop\"\n  else if (instructions[row, \"instruction\"] == \"nop\") {\n    row <- row + 1\n  }\n}\n  \naccumulator\n\n\n[1] 1915\n\n\n\n\nPart 2: Fixing the programme\nTo break the loop, one of the nop instructions in the programme should be a jmp or vice versa. The plan is to swap these out one by one and check if the programme completes. It’s not a sophisticated approach, but it works fast enough (about a second).\nFirst we note that the broken instruction must be one that we visited in Part 1. Also, an instruction of jmp with a value of 0 will get us stuck in a one-line infinite loop, so we avoid that.\n\n\nToggle the code\nlibrary(dplyr)\n\nrows_to_check <- instructions %>%\n  mutate(row_id = row_number()) %>%\n  filter(visited != 0) %>%\n  filter(instruction != \"acc\") %>%\n  filter(!(instruction == \"nop\" & value == 0)) %>%\n  pull(row_id)\n\n\nWe have 93 instruction to check. We modify our code from Part 1 slightly, converting it into a function and returning a list with values completes and accumulator. completes is FALSE as soon as we visit a row twice and TRUE if the number of our next row to visit is greater than the number of rows in the programme.\n\n\nToggle the code\nprogramme_completes <- function(instructions) {\n  \n  row <- 1L\n  accumulator <- 0\n  \n  num_rows <- nrow(instructions)\n  \n  for (i in 1:(num_rows+1)) {\n  \n    if (instructions[row, \"visited\"] != 0) {\n      return(list(completes = FALSE, accumulator = accumulator)) \n    }\n    \n    # +1 on number of times the row is visited\n    instructions[row, \"visited\"] <- instructions[row, \"visited\"] + 1\n  \n    # case when the instruction is \"acc\"\n    if (instructions[row, \"instruction\"] == \"acc\") {\n      accumulator <- accumulator + instructions[row, \"value\"]\n      row <- row + 1\n    }\n  \n    else if (instructions[row, \"instruction\"] == \"jmp\") {\n      row <- row + instructions[row, \"value\"]\n    }\n  \n    else if (instructions[row, \"instruction\"] == \"nop\") {\n      row <- row + 1\n    }\n  \n    if (row > num_rows) {\n      return(list(completes = TRUE, accumulator = accumulator)) \n    }\n  }\n}  \n\n\nWe now loop over the rows we’ve identified to check, breaking the loop as soon as we find a programme that completes. Finally, we extract the accumulator value from the successful programme.\n\n\nToggle the code\ninstructions$visited <- 0\n\nfor (row in rows_to_check) {\n  \n  # modify one row of the instructions,\n  # copying data frame so we don't have to modify it back\n  modified_instructions <- instructions\n  \n  ifelse(instructions[row, 1] == \"jmp\", \n         modified_instructions[row, 1] <- \"nop\", \n         modified_instructions[row, 1] <- \"jmp\") \n  \n  # check if the modified programme completes\n  check_programme <- programme_completes(modified_instructions)\n  \n  if (check_programme$completes) \n    break\n}\n\ncheck_programme$accumulator\n\n\n[1] 944"
  },
  {
    "objectID": "posts/2020-12-09_advent-of-code-2020/index.html#day-9-encoding-error",
    "href": "posts/2020-12-09_advent-of-code-2020/index.html#day-9-encoding-error",
    "title": "Advent of Code 2020",
    "section": "Day 9: Encoding Error",
    "text": "Day 9: Encoding Error\nMy day 9 data\n\nPart 1: Weak Link\nWe have to find the first number in the list which is not the sum of a pair of different numbers in the preceding 25 numbers.\n\n\nToggle the code\ninput <- as.double(readLines(\"data/AoC_day9.txt\")) \n\n\nThere’s a nice trick for finding the pair of numbers in a vector that sum to a target that was doing the rounds on twitter in response to the Day 1 challenge: intersect(input, 2020 - input). For this challenge, we expand on that idea, writing it as a check_sum function. Where there’s more than one pair, it won’t say which pair together, and if the number that’s half the target appears in the addends, it will only appear once in the output. However, for this challenge, we only need to know when there are no pairs that sum to the target, which will be the case when the length of the output of check_sum is 0.\n\n\nToggle the code\ncheck_sum <- function(target, addends) {\n  intersect(addends, target-addends)\n}\n\n\nThen, it’s simply a case of iterating over windows of length 25, checking whether the following number is the sum of a distinct pair in that window, and returning the first one that isn’t.\n\n\nToggle the code\nfind_invalid_num <- function(vec, win = 25) {\n  \n  for (i in (win+1):length(vec)) {\n    check <- check_sum(vec[i], vec[(i-win):(i-1)])\n    \n    if (length(check) == 0) return(vec[i])\n  }\n  \n}\n\nfind_invalid_num(input)\n\n\n[1] 507622668\n\n\n\n\nPart 2: Contiguous set\nFind a contiguous set in the list that sums to the invalid number from Part 1, and add together the largest and smallest number in that range.\nFirst, we note that after a certain point, all numbers in the input are larger than the target, so we don’t need to consider those. We reduce our input vector accordingly.\n\n\nToggle the code\ntarget <- find_invalid_num(input)\n\ninput_reduced <- input[1:(max(which(input <= target)))]\n\n\nTo find the contiguous set in the list that sums to the target, we make use of accumulate() from the purrr package. Let the input list be \\(x = (x_1, x_2,..., x_n)\\). Then accumulate(x, sum) returns \\(a = (x_1, x_1 + x_2,..., \\sum_{j=1}^n x_j)\\). We check whether any element of this vector is equal to the target. If so we index into the input vector appropriately, sum the min and max in the range and we’re done. If not, we consider the sums of all windows starting with the second element of the input list, and so on.\n\n\nToggle the code\ncontiguous_sum <- function(input, target) {\n  \n  len <- length(input)\n  \n  for (i in 1:len) {\n    a <- purrr::accumulate(input[i:len], sum)\n    b <- a == target\n    \n    if (sum(b) == 1) {\n      output_length <- which(b)\n      \n      contiguous_set <- input[i:(i + output_length - 1)]\n      \n      return(sum(range(contiguous_set)))\n    }\n  }\n}\n\ncontiguous_sum(input_reduced, target)\n\n\n[1] 76688505\n\n\nI appreciate that there’s some redundant calculation in this method. The vectors of accumulated sums can contain numbers larger than the target (if writing our own loop, we could break as soon as the accumulated sum got too big). Also, in retrospect, we could have only run accumulate once, then in the second iteration of the loop, subtracted input[1] from the result, in the third iteration subtracted input[2] from that result, etc. However, the function as written is concise and easy to understand, and gets our answer in around a second, so that will do!"
  },
  {
    "objectID": "posts/2020-12-09_advent-of-code-2020/index.html#day-10-adapter-array",
    "href": "posts/2020-12-09_advent-of-code-2020/index.html#day-10-adapter-array",
    "title": "Advent of Code 2020",
    "section": "Day 10: Adapter Array",
    "text": "Day 10: Adapter Array\nMy day 10 data\n\nPart 1: Adapter Distribution\nThis is simply a case of ordering the adapters, prepending 0 and appending the the max in the list plus three, then finding the differences.\n\n\nToggle the code\nlibrary(dplyr)\n\n\n\n\nToggle the code\nadapters <- \n  readLines(\"data/AoC_day10.txt\") %>%\n  as.integer()\n\nadapter_diffs <- c(adapters, 0, max(adapters) + 3) %>% \n  sort() %>%\n  diff()\n\nsum(adapter_diffs == 1) * sum(adapter_diffs == 3)\n\n\n[1] 3034\n\n\n\n\nPart 2: Adapter combinations\nInstead of building up sequences of adapters, we see what we can remove from the full list.\nFirst, we check the diffs: are they just 1 and 3 or are there any 2s?\n\n\nToggle the code\ntable(adapter_diffs)\n\n\nadapter_diffs\n 1  3 \n74 41 \n\n\nWe can’t remove an adapter if its difference with the previous adapter is 3, otherwise the difference between the adapters on either side of it will be too big.\nWhat about diffs of 1? It depends how many ones there are around it. We can check this using the rle() (run length encoding) function\n\n\nToggle the code\nruns <- rle(adapter_diffs)\nruns\n\n\nRun Length Encoding\n  lengths: int [1:48] 3 2 4 2 4 2 4 1 4 2 ...\n  values : num [1:48] 1 3 1 3 1 3 1 3 1 3 ...\n\n\nWhat is the distribution of lengths of sequences of 1s?\n\n\nToggle the code\nruns_table <- table(runs$lengths) \nruns_table\n\n\n\n 1  2  3  4 \n13 14 10 11 \n\n\nWe have at most four diffs of 1 in a row.\nWe need to check that if we remove an adapter, the new differences do not exceed 3. Example sequences really helped me figure out what’s going on here:\n\nIf the diff sequence is …, 3, 1, 3,… (e.g. adapters 1, 4, 5, 8)\n\n1 option to keep as is\nWe cannot remove any adapters\n1 option in total\n\nIf the diff sequence is …, 3, 1, 1, 3,… (e.g. adapters 1, 4, 5, 6, 9)\n\n1 option to keep as is\n1 option to remove one adapter (e.g. the 5)\nwe cannot remove two adapters\n2 options total\n\nIf the diff sequence is …, 3, 1, 1, 1, 3,… (e.g. adapters 1, 4, 5, 6, 7, 10)\n\n1 option to keep as is\n2 options to remove one adapter (e.g. the 5 or 6)\n1 options to remove two adapters (e.g. the 5 and 6)\nWe cannot remove three adapters\n4 options total\n\nIf the diff sequence is …, 3, 1, 1, 1, 1, 3,… (e.g. adapters 1, 4, 5, 6, 7, 8, 11)\n\n1 option to keep as is\n3 options to remove one adapter (e.g. 5, 6, or 7)\n3 options to remove two adapters (e.g. any two of 5, 6, and 7)\nWe cannot remove three adapters\n7 options total\n\n\nFinally, we multiply each run length of difference of 1s with the number of options we have for removing adapters, then take the product of those products.\n\n\nToggle the code\nruns_df <- tibble(lengths = runs$lengths, values = runs$values)\n\noptions <- tibble(lengths = c(1,2,3,4), options = c(1,2,4,7))\n\nruns_df %>%\n  filter(values == 1) %>%\n  left_join(options, by = \"lengths\") %>%\n  summarise(prod_options = prod(options)) %>%\n  pull(prod_options) %>%\n  format(scientific = FALSE) \n\n\n[1] \"259172170858496\""
  },
  {
    "objectID": "posts/2020-12-09_advent-of-code-2020/index.html#day-11-seating-system",
    "href": "posts/2020-12-09_advent-of-code-2020/index.html#day-11-seating-system",
    "title": "Advent of Code 2020",
    "section": "Day 11: Seating System",
    "text": "Day 11: Seating System\nMy day 11 data\n\nPart 1: Changing layout\nMy code for Day 11 runs a little slow (about 10 seconds for Part 1 and 80 seconds for Part 2), so for the sake of being able to rebuild this page quickly as I keep updating it working through the challenges, I will demonstrate this code with the test input provided as an example.\n\n\nToggle the code\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(tidyr)\n\n\nFirst we read in the data and convert it to a matrix (using the datapasta package for the test input):\n\n\nToggle the code\n# layout <- readr::read_tsv(\"data/AoC_day11.txt\", col_names = FALSE)\n\nlayout <- tibble::tribble(\n  ~X1,\n  \"L.LL.LL.LL\",\n  \"LLLLLLL.LL\",\n  \"L.L.L..L..\",\n  \"LLLL.LL.LL\",\n  \"L.LL.LL.LL\",\n  \"L.LLLLL.LL\",\n  \"..L.L.....\",\n  \"LLLLLLLLLL\",\n  \"L.LLLLLL.L\",\n  \"L.LLLLL.LL\"\n  )\n\n\n\n\nToggle the code\n# get number of columns for matrix\nnum_col <- layout %>%\n  mutate(length = str_length(X1)) %>%\n  slice(1) %>%\n  pull(length)\n\n# split layout into characters and turn to vector\nlayout_vec <- layout %>%\n  mutate(X1 = strsplit(X1, split = character(0), fixed = TRUE)) %>%\n  pull(X1) %>%\n  unlist()\n\n# organise into matrix\ninitial_layout <- matrix(layout_vec, ncol = num_col, byrow = TRUE)\n\n\nNext, we write a helper function that, given a matrix and row and column indices, returns a vector of the adjacent seats. We need to take care when indexing into the matrix, so we treat all corner and edge cases separately. Fiddly, but gets the job done.\n\n\nToggle the code\nget_adj <- function(mat, i,j) {\n  \n  nr <- nrow(mat)\n  nc <- ncol(mat)\n  \n  # corner cases\n  if (i == 1 & j == 1) {adj <- c(mat[1,2], mat[2,1:2])}\n  else if (i == 1 & j == nc) {adj <- c(mat[1,(nc-1)], mat[2,(nc-1):nc])}\n  else if (i == nr & j == 1) {adj <- c(mat[nr,2], mat[nr-1,1:2])}\n  else if (i == nr & j == nc) {adj <- c(mat[nr-1, (nc-1):nc], mat[nr, nc-1])}  \n  \n  # edge cases\n  else if (i == 1) {adj <- c(mat[1, c(j-1,j+1)], mat[2, (j-1):(j+1)])}\n  else if (i == nr) {adj <- c(mat[nr, c(j-1,j+1)], mat[nr-1, (j-1):(j+1)])}\n  else if (j == 1) {adj <- c(mat[c(i-1, i+1), 1], mat[(i-1):(i+1), 2])}\n  else if (j == nc) {adj <- c(mat[c(i-1, i+1), nc], mat[(i-1):(i+1), nc-1])}\n  \n  # inside cases\n  else {adj <- c(mat[i-1,(j-1):(j+1)], mat[i,c(j-1,j+1)], mat[i+1,(j-1):(j+1)])}\n  \n  adj\n}\n\n\nOnce we have a vector of surrounding seats, we can apply the rules in the problem to determine whether a given seat needs to change state. The needs_changing helper function does that. It’s overkill at this point to give options to specify the function for finding the vector of seats to check, and the maximum number of occupied seats people can tolerate around them, but (spolier alert) I put in these options when working on the challenge in Part 2.\n\n\nToggle the code\nneeds_changing <- \n  function(mat, i,j, get_surround = get_adj, max_occupied = 4) {\n  \n  surround <- get_surround(mat, i,j)\n  n_occupied <- sum(surround == \"#\")\n  \n  if ((mat[i,j] == \"L\") & (n_occupied == 0)) return(TRUE)\n  \n  else if ((mat[i,j] == \"#\") & (n_occupied >= max_occupied)) {\n    return(TRUE)\n  }\n  \n  else return(FALSE)\n}\n\n\nSince floor spaces don’t change, we only need to consider seats. We save the indices of the seats into a data frame, so we can vectorise over it using tidyverse functions. However, when we’ve determined the seats that need changing, using our needs_changing function, we need to convert those indices from a data.frame into a matrix, in order to index into the layout matrix appropriately and make the changes.\n\n\nToggle the code\nseats <- which(initial_layout != \".\", arr.ind = TRUE)\n\nseats_df <- as.data.frame(seats) %>%\n  rename(i = row, \n         j = col)\n\n\n\n\nToggle the code\nlayout <- initial_layout\niters <- 0\n\n# loop until there are no further changes\nrepeat {\n  \n  change <- 0\n  \n  seats_to_change <- \n    seats_df %>%\n    rowwise() %>%\n    mutate(change_seat = needs_changing(layout,i,j))   \n  \n  change <- sum(seats_to_change$change_seat)\n  \n  if (change == 0) break\n  \n  indices_to_change <- \n    seats_to_change %>%\n    filter(change_seat) %>%\n    select(i,j) %>%\n    as.matrix()  \n\n  layout[indices_to_change] <- \n    setdiff(c(\"L\", \"#\"),  layout[indices_to_change])\n  \n  iters <- iters + 1\n}\n\npart_1_iters <- iters\nsum(layout== \"#\")\n\n\n[1] 37\n\n\nOn the test set, this takes 5 iterations. On the full data set, my answer is 2316, and it took 107 iterations.\n\n\nPart 2: Looking further\nNow, people look to the first seat they can see in each direction, and will change from occupied to unoccupied if five or more of them are occupied.\nThe plan is to write a function that extracts full vectors from a given seat to the edge of the layout matrix in each of the eight directions, then finds the first seat in each of those directions, and finally collects those into a vector of the seats under consideration when determining if a change is needed. Then I can reuse the loop from Part 1, just changing the arguments in the calls to needs_changing.\nHere’s a helper function to get the first seat in a vector looking in one direction:\n\n\nToggle the code\nget_first_seat_from_vec <- function(vec) {\n  \n  if (any(vec %in% c(\"#\", \"L\"))) {\n    return(vec[min(which(vec != \".\"))])\n  }\n  \n  return(NA)\n}\n\n\nNow, if I thought getting adjacent seats to a given seat in Part 1 was fiddly, it’s nothing on getting a vector from a given seat to the edge of the matrix. There are many cases to consider to make we we don’t go out of bounds. In the diagonal directions, first we get a matrix of the indices of the matrix we need, then subset into the matrix accordingly.\n\n\nToggle the code\n# takes a layout matrix (elements \".\", \"#\", \"L\")\n# returns vector with first \"L\" or \"#\" encountered in each direction\nget_first_seat <- function(mat, i,j) {\n  \n  nr <- nrow(mat)\n  nc <- ncol(mat)\n  \n  # North\n  if (i == 1) N <- NA\n  if (i > 1) N <- mat[(i-1):1,j]\n  \n  # South\n  if (i == nr) S <- NA\n  if (i < nr) S <- mat[(i+1):nr,j]\n  \n  # East\n  if (j == nc) E <- NA\n  if (j < nc) E <- mat[i, (j+1):nc]\n  \n  # West\n  if (j == 1) W <- NA\n  if (j > 1) W <- mat[i, (j-1):1]\n  \n  # how far in each direction to edge of matrix\n  to_N <- i - 1\n  to_S <- nr - i\n  to_E <- nc - j\n  to_W <- j - 1\n  \n  # North-West\n  NW_length <- min(to_N, to_W)\n  \n  if (i == 1 | j == 1) NW <- NA\n  else {\n    mat_index <- \n      matrix(c((i-1):(i-NW_length), (j-1):(j-NW_length)), ncol = 2)\n    NW <- mat[mat_index]\n  }\n  \n  # North-East\n  NE_length <- min(to_N, to_E)\n  \n  if (i == 1 | j == nc) NE <- NA\n  else {\n    mat_index <- \n      matrix(c((i-1):(i-NE_length), (j+1):(j+NE_length)), ncol = 2)\n    NE <- mat[mat_index]\n  }\n  \n  # South-East\n  SE_length <- min(to_S, to_E)\n  \n  if (i == nr | j == nc) SE <- NA\n  else {\n    mat_index <- \n      matrix(c((i+1):(i+SE_length), (j+1):(j+SE_length)), ncol = 2)\n    SE <- mat[mat_index]\n  }\n  \n  # South-West\n  SW_length <- min(to_S, to_W)\n  \n  if (i == nr | j == 1) SW <- NA\n  else {\n    mat_index <- \n      matrix(c((i+1):(i+SW_length), (j-1):(j-SW_length)), ncol = 2)\n    SW <- mat[mat_index]\n  }\n\n  # vectors from mat[i,j] to the edge in each direction \n  all_vecs <- \n    (list(N = N, S = S, E = E, W = W, NW = NW, NE = NE, SE = SE, SW = SW))\n  \n  # the first seat in each direction, collapsed to a vector\n  first_seats <- purrr::map_chr(all_vecs, get_first_seat_from_vec)\n  \n  # remove NAs from list and return\n  # (these occur either when starting on an edge, \n  # or when there are no seats in a given direction)\n  return(first_seats[!is.na(first_seats)])\n\n}\n\n\n\n\nToggle the code\nlayout <- initial_layout\niters <- 0\n\n# loop until there are no further changes\nrepeat {\n  \n  change <- 0\n  \n  seats_to_change <- \n    seats_df %>%\n    rowwise() %>%\n    mutate(change_seat = needs_changing(layout,i,j, get_first_seat, 5))   \n  \n  change <- sum(seats_to_change$change_seat)\n  \n  if (change == 0) break\n  \n  indices_to_change <- \n    seats_to_change %>%\n    filter(change_seat) %>%\n    select(i,j) %>%\n    as.matrix()  \n\n  layout[indices_to_change] <- \n    setdiff(c(\"L\", \"#\"),  layout[indices_to_change])\n  \n  iters <- iters + 1\n}\n\npart_2_iters <- iters\nsum(layout== \"#\")\n\n\n[1] 26\n\n\nOn the test set, this takes 6 iterations. On the full data set, my answer is 2128, and it took 87 iterations. Given this is fewer iterations than in Part 1, it must be my code for getting the first seat that’s slowing things down.\nI am unsatisfied both by how many lines of code this has taken as well as the time taken to run. The introduction to Advent of Code says that each challenge has a solution that will complete in at most 15 seconds on ten year old hardware. So clearly there’s a better way of doing this. Perhaps something to revisit in the future."
  },
  {
    "objectID": "posts/2020-12-09_advent-of-code-2020/index.html#next",
    "href": "posts/2020-12-09_advent-of-code-2020/index.html#next",
    "title": "Advent of Code 2020",
    "section": "Next",
    "text": "Next\nI was late to the game, and that was as far as I managed to get in December 2020. I’m looking forward to taking on the challenge again in 2021!"
  },
  {
    "objectID": "posts/2020-12-09_advent-of-code-2020/index.html#last-updated",
    "href": "posts/2020-12-09_advent-of-code-2020/index.html#last-updated",
    "title": "Advent of Code 2020",
    "section": "Last updated",
    "text": "Last updated\n\n2022-11-11 21:32:05 GMT"
  },
  {
    "objectID": "posts/2020-12-09_advent-of-code-2020/index.html#details",
    "href": "posts/2020-12-09_advent-of-code-2020/index.html#details",
    "title": "Advent of Code 2020",
    "section": "Details",
    "text": "Details\n\nsource code, R environment"
  },
  {
    "objectID": "posts/2021-05-26_custom-highlighting-distill-2/index.html#part-1-recap-and-part-2-overview",
    "href": "posts/2021-05-26_custom-highlighting-distill-2/index.html#part-1-recap-and-part-2-overview",
    "title": "Custom syntax highlighting for {distill} part 2",
    "section": "Part 1 recap and part 2 overview",
    "text": "Part 1 recap and part 2 overview\nIn part 1 of this series, Custom syntax highlighting for {distill}: Modifying the theme, I describe how and why I went about the process of finding and modifying the default syntax highlighting for {distill} and how I created a function that wrapped that process for {distilltools}. I discuss the default syntax highlighting theme used on {distill} sites, and how we can modify it by replacing the five colours used there with five colours of our choosing.\nI also outline the four criteria that were important to me as I went about choosing colours for my own syntax highlighting theme:\n\nIt be based on the pink that I use in my logo and elsewhere throughout this site\nIt uses colour theory to pick colours that look appealing together\nIt meets WCAG web accessibility guidelines, by ensuring sufficient colour contrast, i.e. a ratio of 4.5:1, between each of the colours in the theme and this site’s background colour (white)\nThe colours in the palette are colourblind-friendly, i.e. still distinguishable to people with various difference types of colourblindness.\n\nThis post spins out from Part 1 with a brief primer on colour theory and then a deep-dive into the processes, both thought and practical, of choosing colours for my palette that meet the above criteria. I show how I first went about this to derive the palette that’s implemented throughout this site. I also demonstrate a different, entirely R-based, approach to satisfying the criteria, which I decided to try out after learning more about different colour spaces as I was writing up this post. I much preferred the outcome of one approach to the other, but your mileage may vary."
  },
  {
    "objectID": "posts/2021-05-26_custom-highlighting-distill-2/index.html#a-brief-primer-on-colour-theory",
    "href": "posts/2021-05-26_custom-highlighting-distill-2/index.html#a-brief-primer-on-colour-theory",
    "title": "Custom syntax highlighting for {distill} part 2",
    "section": "A brief primer on colour theory",
    "text": "A brief primer on colour theory\n\nColour harmonies\n\n\n\n\n\nFigure 1: An HSL colour wheel. Screen shot from https://www.canva.com/colors/color-wheel/, annotations adapted from https://dev.to/rneha725/hsl-and-hsla-in-css-31j3.\n\n\n\n\nColour theory determines which colours ‘look good’ together, based on their relative position on a colour wheel, such as that in Figure 1, somewhat analogously, I think, to how certain musical intervals sound more pleasing/harmonious than others, depending on the ratio of their frequencies. As shown in Figure 2, there are various different types of colour palettes that are in colour harmony, such as complementary (comprised of colours opposite each other on the wheel), analogous (three colours side by side) and triadic (three colours evenly spaced around the wheel). Note that all the colour schemes are derived from the same twelve colours, spaced evenly around a circle.\n\n\n\n\n\nFigure 2: Harmonious colour combinations. Figure from https://www.widewalls.ch/magazine/color-theory-basics-elements-color-wheel.\n\n\n\n\n\n\nColour spaces\n\nRGB, HSB and HSL\nAnother aspect of colour theory relates to colour spaces, and different ways that colours can be defined. The best known, at least in the context of designing for the web, is RGB (Red Green Blue), which defines a colour by how much of each of those three primary colours it contains, in a range of 0-255. It is the hexidecimal representations of these three numbers that combine to make up the hex code for a colour.\nMore intuitive, however, for adjusting colours, is defining them by HSB (Hue, Saturation, Brightness), also known as HSV (Hue, Saturation, Value). HSB is a simple transformation of the RGB space. Similar to HSB is HSL (Hue, Saturation, Lightness), though HSL is considered an improved over HSB in terms of its perceptual qualities.\nIn HSB, the hue represents the colour type and is a number measured between 0 and 360°; it’s where you are on the colour wheel, ignoring how bright or intense the colour is. Saturation describes the intensity or richness of the hue, measured between 0 and 100%. 100% is the richest version of the colour and 0% is a shade of grey. Brightness measures, you guessed it, the brightness of the colour. Again, it ranges from 0 to 100%, with 0% being black and 100% being a very bright colour (here, black is not the opposite of white). Here’s an excellent article on the HSB system, which also explains how it differs from HSL. The differences between HSB and HSL are also illustrated in Figure 3.\n\n\n\n\n\nFigure 3: HSL and HSB sliders for the pink used throughout this site. Image is a screenshot from http://colorizer.org.\n\n\n\n\nIt’s great to play around with an HSL or HSB colour wheel to get a sense of how harmonious colour schemes are built, and how the colours in them relate to each other on the wheel. I really like the canva colour wheel. It’s pretty simple, with only a few schemes, but it’s nicely designed and easy to use, and the page explains the basics of colour theory too. It’s a fun way to start building a palette. I like how you can pull the dots around the wheel and see how the colours relate, and if you click on a colour in the palette, there are HSL sliders too. Plus, as you move colours around, the background of the page changes colour, which is a nice touch!\n\n\nHCL\nWhilst websites on colour theory for designers tend to focus on either the HSB or HSL spaces, and it’s HSB or HSL wheels/sliders that tend to be built into design and colour software and apps, both spaces suffer from a lack of perceptual uniformity. The RGB rainbow palette is notorious for this. In general, RBG/HSB/HSL palettes are not a good choice for statistical graphics and data visualisation, where colour conveys meaning. For these purposes, the HCL colour space (Hue, Chroma, Luminance) offers a much better alternative. It is much more suitable for capturing human colour perception.\nThere is an R package for working with the HCL colour space, the intuitively named {colorspace} (Zeileis et al. 2020). It has many excellent vignettes, including one about the HCL space and its perceptual superiority over other colour spaces. The package also provides colour palettes and scales for {ggplot2}. There is also support for HCL palettes in base R. The HCL space is also used on I want hue, a site about colours aimed at data scientists, which allows you to generate and refine palettes of optimally distinct colours.\n\n\n\n\n\nFigure 4: My pink on the Luminance-Chroma plane in the HCL space. Image is a screenshot from http://hclwizard.org.\n\n\n\n\nI haven’t seen the HCL space used elsewhere, at least not in the myriad of sites on colour theory for designers or colour/design apps than I use or have read when preparing my theme and this post. Perceptual uniformity is arguably more important in choosing colour palettes for data visualisation, where the colour conveys information about the data, than in picking a few colours that look good together for a syntax highlighting scheme."
  },
  {
    "objectID": "posts/2021-05-26_custom-highlighting-distill-2/index.html#approach-1-colorslurp-and-hsb",
    "href": "posts/2021-05-26_custom-highlighting-distill-2/index.html#approach-1-colorslurp-and-hsb",
    "title": "Custom syntax highlighting for {distill} part 2",
    "section": "Approach 1: ColorSlurp and HSB",
    "text": "Approach 1: ColorSlurp and HSB\n\nBuilding a palette based on my pink, using colour theory\nAs I discuss in Part 1 of this series, I know that I need a palette of five colours to replace the five colours used in the default syntax highlighting scheme that comes with {distill}. The problem with all the colour schemes defined in Figure 2 is that they use a maximum of four colours. But not to worry! We know from colour theory that we can find 12 colours in harmony by taking evenly spaced colours around the HSL or HSB wheel, i.e. colours whose hues are 30° apart, given fixed values for saturation and brightness/lightness. Since we only need five colours, it’s sufficient to find the six colours that are 60° apart, and ignore one of them. Note that for five colours to appear harmonious, we have to respect these angles, not choose five colours that are 72° apart.\nThe main pink that I use in this site has hex #D4006A. I use a great little Mac app called ColorSlurp for building and assessing colour palettes. The basic version is free, though the pro version has great features for testing accessibility - more on that below. In ColorSlurp, I started a new palette with #D4006A as a starting point, then, making sure I was in HSB mode, found its HSB values are 330°, 100%, 83%. Leaving the S and B sliders where they are, the next colour I needed is 60° around the circle, i.e. at 30°, so I moved the H slider to that value and added the resulting orange to the palette. I then repeated that for 90°, 150°, 210° and 270°, giving me two shades of green, a blue and a purple. With a colour selected in ColorSlurp, you can also pull up the colour harmonies tab, , which gives quick access to some of these colours. As I only need five colours, I discarded one of the greens, keeping the one at 150°, which is complementary to the starting pink.\nIf you don’t use ColorSlurp or a similar app, there are many online options for building a palette in this way, for example http://colorizer.org (add a new color to the palette by clicking on the next square down to the right of the sliders). In both ColorSlurp and on colorizer.org, once you have defined a colour by its HSB values, you can read off the hex code, for ease of use in R.\nAt the end of this stage of the process, based purely on my pink and colour theory, my syntax highlighting palette now stood as in Figure 5. In the HSB space, these colours all have a saturation of 100% and a brightness of 83%.\n\n\n\n\n\n\n\n\nFigure 5: Colours for syntax highlighting, starting from my main pink, based only on colour theory.\n\n\n\n\n\n\nAdapting for web accessibility\nAs noted in part 1 of this series, one key feature of the default syntax highlighting scheme for {distill} is that it is optimised for accessibility and colour contrast. According to the Web Content Accessibility Guidelines, at the WCAG AA (minimum contrast) level, this requires that that contrast ratio between text and background colours be at least 4.5:1 for text of 14pt+ (which is the default text size for code in {distill}). The more stringent WCAG AAA (enhanced) level requires a ratio of at least 7:1.\nThe pro version of ColorSlurp includes a contrast checker, as in Figure 6, though there are many websites that also offer this. WebAIM (Web with Accessibility in Mind) has a very handy contrast checker which, like ColorSlurp, also includes sliders for adjusting the colours until the desired contrast is reached. Darkening a colour to improve contrast keeps the hue and saturation the same but reduces the brightness or lightness component (ColorSlurp uses HSB, WebAIM uses HSL).\n\n\n\n\n\nFigure 6: Contrast checking in ColorSlurp\n\n\n\n\nThe pink, blue and purple in the palette created above have a contrast ratio of better than 4.5:1 with the pure white background, but the orange and green do not.\nMy first thought was to keep the pink, blue and purple the same, and to just reduce the brightness of the orange and green until the contrast ratio was a bit better than required. In the HSB space, that gives the palette in Figure 7.\n\n\n\n\n\n\n\n\nFigure 7: Reducing brightness in just the orange and green to achieve desired contrasts.\n\n\n\n\nIt’s not bad, but when I applied that palette as a syntax highlighting scheme, to my eye the pink, blue and purple looked a little too bright relative to the orange.\nMy next thought was to reduce the brightness on all the colours to the level of the least bright colour that passes the accessibility check (the green, at 53%). That gives the palette in Figure 8.\n\n\n\n\n\n\n\n\nFigure 8: Reducing brightness in all colours to the level of the green.\n\n\n\n\nThat looks way too dark for my liking. I don’t think it’s vibrant enough, and, although the colours all have good contrast against the white background, they don’t have much contrast with each other.\nSo, I settled on a compromise position. I reduced the brightness of the original pink, blue and purple from 83% to match the brightness of the accessibility-passing orange (71%), leaving only the green at a brightness of 53%, which it needs to pass the contrast check. This gives the palette in Figure 9. To my eye, the green doesn’t appear considerably more dark/less bright than the other four colours. If anything, the greens in Figure 5 and Figure 8 which both have uniform brighness, look a little too bright compared to the other colours. I guess this is a result of the lack of perceptual uniformity of the HSB space.\n\n\n\n\n\n\n\n\nFigure 9: The palette I settled on for my syntax highlighting scheme.\n\n\n\n\nI’m happy with that, and that’s the syntax highlighting scheme I’ve adopted throughout this site, despite the fact that the palette now doesn’t actually include the pink that I set out to build my scheme around! However, because of the process I’ve followed, the pink that is in the palette does tone well with the brighter pink and I think my site still has a consistent look. In the end, it was more important that all the colours in the palette looked consistent together and met accessibility guidelines.\nI am only just beginning to learn about web accessibility, and I know my site does not yet meet all best practices, but I’m committed to improving in this area. I first became aware of the issue of web accessibility because I follow Silvia Canelón on twitter and I highly recommend you do the same! The a11y project and WebAIM are great places to learn more.\n\n\nChecking for colourblindness\nSome visual impairments require a high colour contrast between text and background colour in order to be able to read content on the web. Another class of visual impairment worth paying attention to when designing palettes is that of colour blindness.\nNick Tierney has some excellent resources about colour and colourblindness and R packages for accessing these. These comprehensive slides cover what colour is and how we perceive it, colourblindness, how to check how palettes/plots appear to those with different types of colourblindness, the HCL space, the {colorspace} package and how to create your own palettes. He also has a short blog post on quickly assessing colour palettes to ensure they’re colourblind-friendly.\nAs recommended in the above posts, I used the {prismatic} package by Emil Hvitfeldt to check how my syntax highlighting palette appears to those with different types of colourblindness:\n\n\nToggle the code\nlibrary(prismatic)\nek_highlight_colours <- c(\"#5B00B6\", \"#005BB6\", \"#008643\", \"#B65B00\", \"#B6005B\")\ncheck_color_blindness(ek_highlight_colours)\n\n\n\n\n\n\n\nFigure 10: Checking my palette for how it appears to those with various types of colourblindness.\n\n\n\n\nThankfully, for all three main types of colourblindess, the five colours in the palette are distinguishable, so no further adjustments are necessary."
  },
  {
    "objectID": "posts/2021-05-26_custom-highlighting-distill-2/index.html#approach-2-an-r-based-hcl-alternative",
    "href": "posts/2021-05-26_custom-highlighting-distill-2/index.html#approach-2-an-r-based-hcl-alternative",
    "title": "Custom syntax highlighting for {distill} part 2",
    "section": "Approach 2: An R-based HCL alternative",
    "text": "Approach 2: An R-based HCL alternative\nThe above sections describe the processes, both thought and practical, that I went through to derive the colour palette for my syntax highlighting scheme, and I’m happy with what I came up with. As I was deriving my scheme, I was working in ColorSlurp and only had a cursory knowledge of the differences between the HSB, HSL and HCL colour spaces.\nHowever, as I was writing up this blog post, I become increasingly curious about alternative approaches I might have taken. In particular, could I have come up with a scheme that met my criteria entirely in R? Given the incredible ecosystem that R is, it should be no surprise that the answer turned out to be yes! So, below is this alternative approach, using the {colorspace}, {coloratio} and {prismatic} packages. Also, whereas the previous approach is based on the HSB colour space, this one uses HCL.\n\nBuilding a palette based on my pink, using colour theory\nThe {colorspace} package uses the HCL color space, so the first task was to convert a hex code into its hue, chroma and luminance components, and make them available for future use, which can be done as follows:\n\n\nToggle the code\nlibrary(colorspace)\npink <- hex2RGB(\"#D4006A\", gamma = FALSE)\npink_hcl <- as(pink, \"polarLUV\")\n\npink_h <- pink_hcl@coords[1, \"H\"]\npink_c <- pink_hcl@coords[1, \"C\"]\npink_l <- pink_hcl@coords[1, \"L\"]\n\n\nThe function from {colorspace} that is going to do the hard work of building a palette with differing hues but constant chroma and luminance (or as close as it can in HCL space) is qualitative_hcl(). By default, you give it the number of colours you want, and it works out equally spaced hues, starting at 0°. To override this default, you can give the h argument a start and end value, c(start, end). Again, I’m going to choose six colours, 60° apart, and discard one of them.2 The start value should be in [0, 60) and the end value should be in [300, 360). Let the hue of our starting pink be pink_h. Then all the colours in the palette are going to have a hue pink_h + 60 * k for some integer k. The following code picks the start and end values we need to pass to h:\n\n\nToggle the code\nseq_60 <- seq(from = -300, to = 300, by = 60)\npink_60 <- seq_60 + pink_h\n\npink_h_lower <- pink_60[which((pink_60 >= 0 & pink_60 < 60))]\npink_h_upper <- pink_60[which((pink_60 >= 300 & pink_60 < 360))]\n\n\nThat’s most of the hard work. Now we build the palette:\n\n\nToggle the code\nhcl_six <- qualitative_hcl(\n  6, \n  h = c(pink_h_lower, pink_h_upper), \n  c = pink_c, \n  l = pink_l\n) \n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 11: Six colours, with hues approximately 60° apart and roughly equal luminance, based around my pink.\n\n\n\n\nThe only personal decision I make in this section is which of these six colours to discard. Removing the first of the greens gives me the palette in Figure 12.\n\n\n\n\n\n\n\n\nFigure 12: As in the previous figure but minus a green and rearranged.\n\n\n\n\n\n\n\n\n\n\n\n\n\nUpdate: May 27th 2021\n\n\n\n\n\nSince publishing this post, Achim Zeileis, the author of the {colorspace} package, got in touch with me on twitter to offer a bit more insight into what’s going on with this palette. The hcl_six palette does not, as I originally stated, have constant chroma. I have corrected the text above. Not all combinations of Hue/Chroma/Luminance exist in HCL space. At the luminance of my pink (~46) not many other hues can have such high chroma (~118), as demonstrated in Figure 13.\n\n\n\n\n\nFigure 13: Hues and Chromas in HCL space at the Luminance of my pink\n\n\n\n\nqualitative_hcl() struggles in such circumstances, though does try to keep the luminance of the palette constant.\n\n\n\n\n\nAdapting for web accessibility\nWhen I was developing my scheme, I used my trusted ColorSlurp app to adjust colours to ensure they met WCAG standards of web accessibility. In writing up this post, I since learnt about web resources to do the same (e.g. WebAIM contrast checker) and now, for this section, I’ve discovered the {coloratio} by Matt Dray and {savonliquide} by Mohamed El Fodil Ihaddaden packages that can do this in R.\nBoth packages have much to recommend them. {savonliquide} has the advantage of being on CRAN, and provides a toolbox that allows the user to implement accessibility-related concepts, including, but not limited to, contrast checking. {coloratio} is GitHub only, and only for contrast checking, but it has some additional functionality in that area above {savonliquide}, such as quick plotting of the colours in contrast, and a function, cr_choose_bw() that chooses which of black or white has the better contrast ratio with a user supplied colour (which, incidentally, I use to automatically choose the text colour when highlighting words with different background colours, e.g. #D4006A vs #00D46A).3\nBelow, I use the cr_get_ratio function from coloratio to check the colour contrasts of each colour in the palette. Because it’s not vectorised, I use this in conjunction with map2_dbl from {purrr} to get all the contrasts at once.\nIf any of the contrasts are less than 4.5, I then call on the darken() function from {colorspace}, which adjusts each colour in the palette to make it, you guessed it, a bit darker, therefore improving the contrast ratio. I loop over these checking and darkening iterations until all colours in the palette have a contrast ratio of at least 4.5:1 compared to white. Here is the code that achieves this:\n\n\nToggle the code\nlibrary(coloratio)\nlibrary(purrr)\n\npalette <- hcl_six[c(6, 1, 3:5)]\ncontrasts <- map2_dbl(\n    palette, \n    \"white\", \n    ~cr_get_ratio(.x, .y, quiet = TRUE)\n  )\nmin_contrast <- 4.5\nany_too_light <- any(contrasts < min_contrast)\n\nwhile (any_too_light) {\n  palette <- darken(palette, amount = 0.05)\n  contrasts <- map2_dbl(\n      palette, \n      \"white\", \n      ~cr_get_ratio(.x, .y, quiet = TRUE)\n    )\n  any_too_light <- any(contrasts < min_contrast)\n}\n\n\nAt the end of the process, the palette looks like this:\n\n\n\n\n\n\n\n\nFigure 14: An HCL palette where all colours have a contrast ratio of 4.5:1 or better against white.\n\n\n\n\n\n\nChecking for colourblindness\nAs before, we use {prismatic} to check how the palette appears to those with various types of colourblindess. Whilst R can help us visualise this, we still need to use our judgement as to whether the output is acceptable. I believe, in Figure 15, it is.\n\n\n\n\n\nFigure 15: Checking how the darkened HCL palette appears to those with various types of colourblindness.\n\n\n\n\n\n\nBut, do I like it?\nGoing through the process of building a colour palette that meets my criteria purely in R, in as automated, reproducible and adaptable way as possible has been a great learning experience for me, and hopefully something that will be useful to others. I don’t much like the palette it produced, though, especially in comparison to the one I came up with previously. Although the HCL-based palette probably has slightly better theoretical perceptual qualities, I prefer the vibrancy of the colours in the palette I came up with using my first approach, and that’s the one I’ve adopted on this site."
  },
  {
    "objectID": "posts/2021-05-26_custom-highlighting-distill-2/index.html#back-to-part-1",
    "href": "posts/2021-05-26_custom-highlighting-distill-2/index.html#back-to-part-1",
    "title": "Custom syntax highlighting for {distill} part 2",
    "section": "Back to part 1",
    "text": "Back to part 1\nNow that I have chosen my colour palette, head back to part 1 for details of how to modify the default {distill} syntax highlighting theme to incorporate them, and how to apply the custom theme to a {distill} site."
  },
  {
    "objectID": "posts/2021-05-26_custom-highlighting-distill-2/index.html#last-updated",
    "href": "posts/2021-05-26_custom-highlighting-distill-2/index.html#last-updated",
    "title": "Custom syntax highlighting for {distill} part 2",
    "section": "Last updated",
    "text": "Last updated\n\n2022-11-11 22:27:46 GMT"
  },
  {
    "objectID": "posts/2021-05-26_custom-highlighting-distill-2/index.html#details",
    "href": "posts/2021-05-26_custom-highlighting-distill-2/index.html#details",
    "title": "Custom syntax highlighting for {distill} part 2",
    "section": "Details",
    "text": "Details\n\nsource code, R environment"
  },
  {
    "objectID": "posts/2021-05-25_custom-highlighting-distill-1/index.html#tldr",
    "href": "posts/2021-05-25_custom-highlighting-distill-1/index.html#tldr",
    "title": "Custom syntax highlighting for {distill} part 1",
    "section": "TL;DR",
    "text": "TL;DR\nThe {distill} package for R can be used to build easy-to-maintain websites written only in R Markdown, such as this one.2\nI wrote a function to modify the default syntax highlighting theme. This modify_default_highlighting function is now part of the {distilltools} package.\nHere’s the function in action, to get the theme used on this site:\n\n\nToggle the code\n# get distilltools, requires remotes >= 2.2\nremotes::install_github(\"EllaKaye/distilltools\") \n\nlibrary(distilltools)\nmodify_default_highlighting(\n  name = \"ek_syntax_highlighting\",\n  numeric = \"#B6005B\", # replaces the default red\n  strings = \"#008643\", # replaces the default green\n  functions = \"#005BB6\", # replaces the default purple\n  control = \"#5B00B6\", # replaces the default blue\n  constant = \"#B65B00\" # replaces the default brown\n)\n\n\nAnd here’s the theme in action:\n\n\nToggle the code\nlibrary(dplyr)\nlibrary(palmerpenguins)\n\npenguins %>%\n  mutate(\n    long_flipper = case_when(\n      species == \"Adelie\" & flipper_length_mm > 195 ~ TRUE,\n      species == \"Chinstrap\" & flipper_length_mm > 200 ~ TRUE,\n      species == \"Gentoo\" & flipper_length_mm > 225 ~ TRUE,\n      TRUE ~ FALSE\n    )\n  ) %>%\n  mutate(\n    long_bill = case_when(\n      species == \"Adelie\" & bill_length_mm > 42 ~ TRUE,\n      species == \"Chinstrap\" & bill_length_mm > 52 ~ TRUE,\n      species == \"Gentoo\" & bill_length_mm > 50 ~ TRUE,\n      TRUE ~ FALSE\n    )\n  )\n\n\nThis is the first in a series of two posts on implementing a custom syntax highlighting theme for a website or blog built with {distill}. Read on here for why and how this function was built, what it does and doesn’t do, and its inclusion in the {distilltools} package. This post also outlines the criteria that were important to me when choosing colours for my theme, but take a look at part 2, Custom syntax highlighting for {distill}: Creating the palette, for a deep dive into considerations about colour choices, in respect to both colour theory and accessibility, and how I ensured my criteria were met."
  },
  {
    "objectID": "posts/2021-05-25_custom-highlighting-distill-1/index.html#but-first-the-default",
    "href": "posts/2021-05-25_custom-highlighting-distill-1/index.html#but-first-the-default",
    "title": "Custom syntax highlighting for {distill} part 1",
    "section": "But first, the default",
    "text": "But first, the default\n\nIn praise of the default\nBefore I delve into how to create a custom syntax highlighting scheme, I want to take a minute to admire the default. The authors of {distill}, in particular Alison Hill, have thought and worked hard to ensure that {distill} provides a good user experience, both for the site’s author AND for those reading it. One of the key considerations for the latter is a default syntax highlighting scheme with colours that are optimised for accessibility and colour contrast. I say more about what that means below and in part 2. Also, it appears that the colours in the scheme work well together, and overall, on the many {distill} websites where I’ve seen the scheme used, I think it looks really good! For a great example of the default in action, check out this code-chunk-heavy post by Tom Mock.\n\n\nSo, why change?\n\n\n\nWhen I used the default syntax highlighting theme on my site I found, to my eye, that the red used for numeric variables clashed with the bright pink (closest colour name “razzmatazz”) I’ve used in my logo and elsewhere throughout the site. So, I decided to tweak the default theme swapping the red for my pink and, to match it, more vibrant versions of the remaining colours.\n\n\nDistill/pandoc documentation\nMy first task was to find out whether this was possible, and if, so, how. Thankfully, the {distill} documentation contains a section on syntax highlighting, showing that there is an option to give distill_article a path to a custom .theme file. The linked pandoc documentation on syntax highlighting demonstrates how to use pandoc in the command line to save a personal version of the pygments highlighting theme. The documentation points out that that copy of the pygments .theme file can then be edited to create a custom theme.\n\n\nFinding and saving the default\nOnce I had a general strategy of copying and editing an existing .theme file, my next task was to find the .theme file for the default used in {distill}, because that’s what I’d already decided to take as my starting point.\nI cloned the distill repo from GitHub and opened it in RStudio.3 From there I began my detective work with one of my favourite RStudio features, ‘Find in Files’ (⇧ + ⌘ + F on a Mac), which searches across all files in a project. I searched for “highlight” and followed various trails until I discovered that the default is called arrow.theme and is stored in inst/rmarkdown/templates/distill_article/resources/. Thankfully, because it’s in the inst folder, the file is accessible to users who have the {distill} package installed. In the RStudio project for my website, I created a new script, syntax_highlighting.R, in the R folder I have in my root directory, then I ran the following to save a copy of arrow.theme into my website’s root directory:\n\n\nToggle the code\narrow_theme_path <- system.file(\n  \"rmarkdown/templates/distill_article/resources/arrow.theme\", \n  package = \"distill\"\n)\n\nfile.copy(arrow_theme_path, \"arrow.theme\")\n\n\nWhen I had run that once, I commented out the above lines. I don’t want any future changes in arrow.theme in {distill} to break what I do next.\n\n\nCloser inspection of the default\nFrom there I could open up my copy of the arrow.theme file and manually inspect it. I use a great Mac app for building colour palettes, ColorSlurp.4 The basic version is free, though the pro version has useful features for testing accessibility - more on that in part 2. I set up a new palette in ColorSlurp and, for each hex colour code I encountered, I saved it there.\nThere are 29 types of text-styles in the theme, of which:\n\n8 are assigned a grey, #5E5E5E, things like Comment and Documentation\n1 is off-black, #111111, Variable\n3 are blue, #007BA5, Other, ControlFlow and Keyword\n4 are green, #20794D, corresponding to various types of string\n1 is purple, #4758AB, Function\n7 are red, #AD0000, a mix of numeric (e.g. BaseN, Float) and things like Alert and Error\n1 is a brown, #8F5902, for Constant\n4 types are not assigned a colour - they are left as null\n\nI was happy to stick with the groupings, grey, off-black and null in the default, so now I knew I had to pick five colours for my theme."
  },
  {
    "objectID": "posts/2021-05-25_custom-highlighting-distill-1/index.html#building-my-own-palette",
    "href": "posts/2021-05-25_custom-highlighting-distill-1/index.html#building-my-own-palette",
    "title": "Custom syntax highlighting for {distill} part 1",
    "section": "Building my own palette",
    "text": "Building my own palette\nI had four criteria for building a colour palette to use for my syntax highlighting theme:\n\nIt be based on the pink that I use in my logo and elsewhere throughout this site\nIt uses colour theory to pick colours that look appealing together\nIt meets WCAG web accessibility guidelines, by ensuring sufficient colour contrast, i.e. a ratio of 4.5:1, between each of the colours in the theme and this site’s background colour (white)\nThe colours in the palette are colourblind-friendly, i.e. still distinguishable to people with various difference types of colourblindness.\n\nI was originally going to write up how I went about building such a palette, both in terms of the thought process and tools used, as part of this post, but it was getting a little long5, so I’ve spun it out into a separate post, Custom syntax highlighting for {distill} part 2: Creating the palette.\nAt the end of the process, the palette for my syntax highlighting scheme is as in Figure 1.\n\n\n\n\n\n\n\n\nFigure 1: The palette I settled on for my syntax highlighting scheme."
  },
  {
    "objectID": "posts/2021-05-25_custom-highlighting-distill-1/index.html#modifying-arrow.theme",
    "href": "posts/2021-05-25_custom-highlighting-distill-1/index.html#modifying-arrow.theme",
    "title": "Custom syntax highlighting for {distill} part 1",
    "section": "Modifying arrow.theme",
    "text": "Modifying arrow.theme\nWith all the pieces in place, it’s now just a case of swapping out the default colour codes for our own choices. Although it’s possible to manually edit the arrow.theme file we now have in our directory, to aid reproducibility, and with a view to writing this up as a function, I edited it using R code instead. I read in the file, substituted the hex codes, then saved the resulting theme into a new ek_syntax_highlighting.theme file (leaving arrow.theme unchanged). Below are two approaches, one using base R, the other in the tidyverse, that I put in my syntax_highlighting.R script.\n\n\nToggle the code\n# read in the default theme\ntheme <- readLines(\"arrow.theme\")\n\n# base R approach\ntheme <- gsub(\"#AD0000\", \"#B6005B\", theme) # red -> pink\ntheme <- gsub(\"#8f5902\", \"#B65B00\", theme) # brown -> brown \ntheme <- gsub(\"#007BA5\", \"#5B00B6\", theme) # blue -> purple\ntheme <- gsub(\"#20794D\", \"#B65B00\", theme) # green -> green\ntheme <- gsub(\"#4758AB\", \"#005BB6\", theme) # purple -> blue\n\n# alternatively, tidyverse approach\nlibrary(stringr)\nlibrary(magrittr)\n\ntheme <- readLines(\"arrow.theme\") %>%\n   str_replace_all(\"#AD0000\", \"#B6005B\") %>% # red -> pink\n   str_replace_all(\"#8f5902\", \"#B65B00\") %>% # brown -> brown \n   str_replace_all(\"#007BA5\", \"#5B00B6\") %>% # blue -> purple\n   str_replace_all(\"#20794D\", \"#008643\") %>% # green -> green\n   str_replace_all(\"#4758AB\", \"#005BB6\")     # purple -> blue\n\n# save new theme\nwriteLines(theme, \"ek_syntax_highlighting.theme\")\n\n\nI now have the file ek_syntax_highlighting.theme in my root directory, with my colour choices.\nIt is, of course, possible to modify it further, either manually or by making further substutions in the code above. There is a quirk, though: if I swap one of the default hex codes for my own colour choice, that implements just fine, but if I swap any of the nulls for a colour, that doesn’t show up when I apply the theme."
  },
  {
    "objectID": "posts/2021-05-25_custom-highlighting-distill-1/index.html#wrapping-in-a-distilltools-function",
    "href": "posts/2021-05-25_custom-highlighting-distill-1/index.html#wrapping-in-a-distilltools-function",
    "title": "Custom syntax highlighting for {distill} part 1",
    "section": "Wrapping in a {distilltools} function",
    "text": "Wrapping in a {distilltools} function\nWhen I figure out code to do something that I think I might want to do again, or think others might find useful, I generally like to write it up as a function, and that’s what I’ve done with the above, wrapping it in a function called modify_default_highlighting and putting it in the {distilltools} package. {distilltools} is in the very early stages of development, an (expanding) collection of tools to support the creation and styling of content on websites created using {distill}.\nWhen I first announced the package, I included in the ‘future functionality’ section of the package README the intention to add a create_highlight_theme function. I don’t think what I’ve done is quite versatile or fully-featured enough to warrant that name. Instead, I called it modify_default_highlighting because that’s all it does, allowing you to swap out the five colours in the default scheme for five colours of your choosing. It does, however, create a .theme file in your working directory, that can be further edited manually, or with your own R code, if further modifications are desired.\nThe first argument to modify_default_highlighting is name, the name you want to give your theme (which will create the file name.theme). It then takes five colour arguments, which can be specified either in the hex form “#RRGGBB” or as a named colour, from the colour names in grDevices::colors(). For a list of the colour names available in R, see page 3 of the R color cheatsheet for a one page summary, or Colors in R for a slightly less visually overwhelming list. The final argument, overwrite (defaults to TRUE) specifies whether to overwrite name.theme if it already exists in the working directory. Here’s the function in action again, this time using colour names (note that I have not tested the visual properties of this as a palette, just dropped in some colour names into the function):\n\n\nToggle the code\nlibrary(distilltools)\nmodify_default_highlighting(\n  name = \"ek_syntax_highlighting\",\n  numeric = \"deeppink\", # replaces the default red\n  strings = \"forestgreen\", # replaces the default green\n  functions = \"darkorchid3\", # replaces the default purple\n  control = \"royalbkue3\", # replaces the default blue\n  constant = \"darkorange1\" # replaces the default brown\n)"
  },
  {
    "objectID": "posts/2021-05-25_custom-highlighting-distill-1/index.html#using-the-theme",
    "href": "posts/2021-05-25_custom-highlighting-distill-1/index.html#using-the-theme",
    "title": "Custom syntax highlighting for {distill} part 1",
    "section": "Using the theme",
    "text": "Using the theme\nOnce you have you custom .theme file, you’ll want to apply it to your site. According to the {distill} documentation, you can apply a syntax highlighting theme with the following YAML:\n---\noutput:\n  distill::distill_article:\n    highlight: my_highlighting.theme\n---  \nHere, the available options for highlight include default, rstudio (the default RStudio editor theme), and the haddock, kate, monochrome, pygments and tango pandoc highlighting themes. Also, most importantly for us, it can also take the path to a .theme file.\nPresumably, we should be able to add this to our _site.yml file to have the theme apply site-wide (though note you’ll have to rebuild the site and re-knit any posts where you want to it apply). However, that’s not working for me. I have raised an issue about it. If you face the same problem, it would be helpful if you could comment there too.\nThere is a workaround, though, which is that the above YAML can also be included in individual .Rmd articles, in which case the theme applies just fine, though note that if your .theme file is in you root directory, you’ll need to give the full path to it.6 And if it sounds like a bit of a pain to have to add that every time you write a new post, consider creating a template for your posts, including those lines, and then starting new posts with the {distilltools} function create_post_from_template().7"
  },
  {
    "objectID": "posts/2021-05-25_custom-highlighting-distill-1/index.html#last-updated",
    "href": "posts/2021-05-25_custom-highlighting-distill-1/index.html#last-updated",
    "title": "Custom syntax highlighting for {distill} part 1",
    "section": "Last updated",
    "text": "Last updated\n\n2022-11-11 22:27:29 GMT"
  },
  {
    "objectID": "posts/2021-05-25_custom-highlighting-distill-1/index.html#details",
    "href": "posts/2021-05-25_custom-highlighting-distill-1/index.html#details",
    "title": "Custom syntax highlighting for {distill} part 1",
    "section": "Details",
    "text": "Details\n\nsource code, R environment"
  },
  {
    "objectID": "posts/2017-06-17_n-letter-words/index.html",
    "href": "posts/2017-06-17_n-letter-words/index.html",
    "title": "n_letter_words and a personal (publicly available) package",
    "section": "",
    "text": "There’s a little R function that I wrote and packaged up to generate a vector or data frame of words of a given length. I find it useful in a wide variety of contexts and thought other might too. To kick off my new blog, here’s a post about it.\nThe function, n_letter_words, came about because I wanted to be able to generate row and column names for a large matrix - didn’t matter what they were, as long as they were unique. Since I was in the habit of using the built-in LETTERS vector to do this for small matrices, I naturally thought of using combinations of letters to do this in a larger case. In figuring out how to do this, as is so often the case, it was stackoverflow to the rescue. There, I learnt about expand.grid and could then use some tidyverse tools to get the vector I was after:\nSorted! At least I thought so, until, a couple of months later, when I wanted to generate names for a 1000*1000 matrix, and realised both that I’d forgotten the expand.grid trick, and once I’d re-found the stackoverflow post, that it didn’t give me enough words. That was enough to make it worth writing a function, taking n as an argument, that gives all ‘words’ of length \\(n\\).\nWriting functions always makes me think of what other arguments might be useful. What if we want something between the 676 two-letter words and 17,576 three-letter words (or the 456,976 four-letter words, etc)? Hence the argument num_letters, which can be set between 1 and 26, and results in a total of num_letters\\(^n\\) words. By default, the function returns a tibble, but setting as_vector = TRUE does what you’d expect. And I threw in a case argument too.\nNow that I had my function, what to do with it? I remembered articles I’d read about the usefulness of making and sharing a personal package. Now seemed like the time to do that myself.\nSo, here is my personal package, EMK. If you think that n_letter_words might be of use to you, then feel free to install!\nSome examples of n_letter_words:\nFor now, my personal package has only this one function, but watch this space! No doubt I’ll be adding more that I find useful. Perhaps, you’ll find them useful too.\nIncidentally, none of the above would have happened if I’d just thought, for my test matrix A, to set dimnames(A) <- list(1:nrow(A), 1:ncol(A))!"
  },
  {
    "objectID": "posts/2017-06-17_n-letter-words/index.html#last-updated",
    "href": "posts/2017-06-17_n-letter-words/index.html#last-updated",
    "title": "n_letter_words and a personal (publicly available) package",
    "section": "Last updated",
    "text": "Last updated\n\n2022-11-11 21:27:19 GMT"
  },
  {
    "objectID": "posts/2017-06-17_n-letter-words/index.html#details",
    "href": "posts/2017-06-17_n-letter-words/index.html#details",
    "title": "n_letter_words and a personal (publicly available) package",
    "section": "Details",
    "text": "Details\n\nsource code, R environment"
  },
  {
    "objectID": "talks.html",
    "href": "talks.html",
    "title": "Ella Kaye",
    "section": "",
    "text": "TALKS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow to get help in R\n\n\nTips for looking for answers and asking questions about R\n\n\n\nElla Kaye\n\n\nOct 29, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWorking with text in R\n\n\nAn overview of a range of packages for working with text in R.\n\n\n\nElla Kaye\n\n\nOct 5, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSetting up your PhD (or other research project) as an R package\n\n\nHow I set up my PhD as an R package\n\n\n\nElla Kaye\n\n\nAug 23, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRanking items scalably with the Bradley-Terry model\n\n\nIntroducing the {BradleyTerryScalable} package\n\n\n\nElla Kaye\n\n\nJul 6, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn overview of htmlwidgets\n\n\nA brief overview of using htmlwidgets in R\n\n\n\nElla Kaye\n\n\nMay 25, 2017\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "talks/2018-08-23_phd-as-package/index.html",
    "href": "talks/2018-08-23_phd-as-package/index.html",
    "title": "Setting up your PhD (or other research project) as an R package",
    "section": "",
    "text": "slides  materials"
  },
  {
    "objectID": "talks/2018-08-23_phd-as-package/index.html#overview",
    "href": "talks/2018-08-23_phd-as-package/index.html#overview",
    "title": "Setting up your PhD (or other research project) as an R package",
    "section": "Overview",
    "text": "Overview\nIn this talk, I will try to convince you that if you have any of your own data or write any of your own R functions, then you should put them into an R package. Benefits include reproducibility and keeping everything together and accessible. Also, it’s really easy to do, and to prove it, I will build a package from scratch before your very eyes. I will also introduce the bookdown package for writing reports and even your thesis. Filled with tips and tricks from my own experiences, this talk could save you hours!"
  },
  {
    "objectID": "talks/2018-08-23_phd-as-package/index.html#event-details",
    "href": "talks/2018-08-23_phd-as-package/index.html#event-details",
    "title": "Setting up your PhD (or other research project) as an R package",
    "section": "Event details",
    "text": "Event details\nEvent: Birmingham R User Group\nDate: August 8th, 2018\nTime: 18:00-20:00 GMT+1\nLocation: Faraday Wharf, Innovation Birmingham Campus, Holt Street, Birmingham Science Park, B7 4BB"
  },
  {
    "objectID": "talks/2018-08-23_phd-as-package/index.html#key-points",
    "href": "talks/2018-08-23_phd-as-package/index.html#key-points",
    "title": "Setting up your PhD (or other research project) as an R package",
    "section": "Key points",
    "text": "Key points\n\nPut your data and functions in an R package\nR packages are good for reproducibility, for keeping everything together and for sharing\nExisting R packages such as {usethis}, {devtools} {roxygen2} and {testthat} take the friction out of writing your own packages"
  },
  {
    "objectID": "talks/2018-08-23_phd-as-package/index.html#slides",
    "href": "talks/2018-08-23_phd-as-package/index.html#slides",
    "title": "Setting up your PhD (or other research project) as an R package",
    "section": "Slides",
    "text": "Slides\n\n\nKeyboard shortcuts for slideshow (once you’ve clicked inside it):\n\nUse ← and → to navigate through the slides.\nUse o for an overview of all slides.\nUse h to see a list of other shortcuts\n\nf to toggle full screen not working, but the rest are fine.\nFor full screen slides, go to slides then press f."
  },
  {
    "objectID": "talks/2020-10-29_how-to-get-help-in-r/index.html",
    "href": "talks/2020-10-29_how-to-get-help-in-r/index.html",
    "title": "How to get help in R",
    "section": "",
    "text": "slides  materials  video"
  },
  {
    "objectID": "talks/2020-10-29_how-to-get-help-in-r/index.html#overview",
    "href": "talks/2020-10-29_how-to-get-help-in-r/index.html#overview",
    "title": "How to get help in R",
    "section": "Overview",
    "text": "Overview\nThis session will be led by Ella Kaye - an R enthusiast and statistics PhD researcher at the University of Warwick. In the session, Ella will talk us through different ways to get help when you get stuck on a problem in R. We’ll cover how and where to look for answers and how to ask and post good questions that make it easy for others to help you, including a demo of the excellent reprex and datapasta packages. So whether you’re an R novice or more experienced R user, hopefully there’ll be some useful tips for you!"
  },
  {
    "objectID": "talks/2020-10-29_how-to-get-help-in-r/index.html#event-details",
    "href": "talks/2020-10-29_how-to-get-help-in-r/index.html#event-details",
    "title": "How to get help in R",
    "section": "Event details",
    "text": "Event details\nEvent: R Ladies Coventry (the inaugural talk)\nDate: October 29th, 2020\nLocation: Zoom\nI gave a very slightly updated version of the talk again three months later:\nEvent: bseeR\nDate: January 28th, 2021\nLocation: Microsoft Teams"
  },
  {
    "objectID": "talks/2020-10-29_how-to-get-help-in-r/index.html#key-points",
    "href": "talks/2020-10-29_how-to-get-help-in-r/index.html#key-points",
    "title": "How to get help in R",
    "section": "Key points",
    "text": "Key points\n\nWhen faced with a question/problem, have a good look for an answer in R itself and/or online\nDon’t be shy about asking questions!\nWrite reproducible examples, best with the {reprex} package\nGive thought to where you ask/post your question\nGive back by helping others"
  },
  {
    "objectID": "talks/2020-10-29_how-to-get-help-in-r/index.html#slides",
    "href": "talks/2020-10-29_how-to-get-help-in-r/index.html#slides",
    "title": "How to get help in R",
    "section": "Slides",
    "text": "Slides\n\n\nKeyboard shortcuts for slideshow (once you’ve clicked inside it):\n\nUse ← and → to navigate through the slides.\nUse o for an overview of all slides.\nUse h to see a list of other shortcuts\n\nf to toggle full screen not working, but the rest are fine.\nFor full screen slides, go to slides then press f."
  },
  {
    "objectID": "talks/2019-10-05_working-with-text-in-r/index.html",
    "href": "talks/2019-10-05_working-with-text-in-r/index.html",
    "title": "Working with text in R",
    "section": "",
    "text": "slides  materials  video"
  },
  {
    "objectID": "talks/2019-10-05_working-with-text-in-r/index.html#overview",
    "href": "talks/2019-10-05_working-with-text-in-r/index.html#overview",
    "title": "Working with text in R",
    "section": "Overview",
    "text": "Overview\nTranscending its origins as a programming language for statistics, R provides excellent tools for working with text. This tidyverse-based talk will provide an overview of some of the fantastic packages available for this, including (but not limited to) stringr, RVerbalExpressions, tidytext, wordcloud and ggwordcloud."
  },
  {
    "objectID": "talks/2019-10-05_working-with-text-in-r/index.html#event-details",
    "href": "talks/2019-10-05_working-with-text-in-r/index.html#event-details",
    "title": "Working with text in R",
    "section": "Event details",
    "text": "Event details\nEvent: RLadies Toronto\nDate: October 5th, 2019\nTime: 14:00-16:00 EDT\nLocation: Stewart Building, 149 College Street, Toronto\nI then gave an updated version of the talk a few months later (links at the top relate to this version):\nEvent: RLadies Tbilisi\nDate: July 4th, 2020\nTime: 09:00-10:00 GMT\nLocation: Zoom"
  },
  {
    "objectID": "talks/2019-10-05_working-with-text-in-r/index.html#slides",
    "href": "talks/2019-10-05_working-with-text-in-r/index.html#slides",
    "title": "Working with text in R",
    "section": "Slides",
    "text": "Slides\n\n\nKeyboard shortcuts for slideshow (once you’ve clicked inside it):\n\nUse ← and → to navigate through the slides.\nUse o for an overview of all slides.\nUse h to see a list of other shortcuts\n\nf to toggle full screen not working, but the rest are fine.\nFor full screen slides, go to slides then press f."
  },
  {
    "objectID": "talks/2017-07-06_introducing-BradleyTerryScalable/index.html",
    "href": "talks/2017-07-06_introducing-BradleyTerryScalable/index.html",
    "title": "Ranking items scalably with the Bradley-Terry model",
    "section": "",
    "text": "slides (2017)  materials (2017)\nslides (2022)  materials (2022)\npackage"
  },
  {
    "objectID": "talks/2017-07-06_introducing-BradleyTerryScalable/index.html#overview",
    "href": "talks/2017-07-06_introducing-BradleyTerryScalable/index.html#overview",
    "title": "Ranking items scalably with the Bradley-Terry model",
    "section": "Overview",
    "text": "Overview\nI am very excited to be introducing the package BradleyTerryScalable at useR!2017. The package is available on GitHub.\nBradleyTerryScalable is an R package for fitting the Bradley-Terry model to pair-comparison data, to enable statistically principled ranking of a potentially large number of objects.\nGiven a number of items for which we have pair-comparison data, the Bradley-Terry model assigns a ‘strength’ parameter to each item. These can be used to rank the items. Moreover, they can be used to determine the probability that any given item will ‘beat’ any other given item when they are compared. Further details of the mathematical model, and the algorithms used to fit it, are available in the package vignette.\n\n\n\n\n\n\nUpdate: 2022\n\n\n\n\n\nI reworked this presentation for a job interview. The 2022 slides and materials are for that version. It’s a little shorter, at 10 minutes rather than 15 minutes. The main difference, however, is in the much-improved slidecraft and style!"
  },
  {
    "objectID": "talks/2017-07-06_introducing-BradleyTerryScalable/index.html#event-details",
    "href": "talks/2017-07-06_introducing-BradleyTerryScalable/index.html#event-details",
    "title": "Ranking items scalably with the Bradley-Terry model",
    "section": "Event details",
    "text": "Event details\nEvent: useR!2017\nDate: July 6th, 2017\nTime: 11:36 AM\nLocation: Brussels, Belgium"
  },
  {
    "objectID": "talks/2017-07-06_introducing-BradleyTerryScalable/index.html#slides-2017",
    "href": "talks/2017-07-06_introducing-BradleyTerryScalable/index.html#slides-2017",
    "title": "Ranking items scalably with the Bradley-Terry model",
    "section": "Slides (2017)",
    "text": "Slides (2017)\n\n\nKeyboard shortcuts for slideshow (once you’ve clicked inside it):\n\nUse ← and → to navigate through the slides.\nUse o for an overview of all slides.\nUse h to see a list of other shortcuts\n\nf to toggle full screen not working, but the rest are fine.\nFor full screen slides, go to slides then press f."
  },
  {
    "objectID": "talks/2017-07-06_introducing-BradleyTerryScalable/index.html#slides-2022",
    "href": "talks/2017-07-06_introducing-BradleyTerryScalable/index.html#slides-2022",
    "title": "Ranking items scalably with the Bradley-Terry model",
    "section": "Slides (2022)",
    "text": "Slides (2022)"
  },
  {
    "objectID": "talks/2017-05-25_overview-of-htmlwidgets/index.html",
    "href": "talks/2017-05-25_overview-of-htmlwidgets/index.html",
    "title": "An overview of htmlwidgets",
    "section": "",
    "text": "materials"
  },
  {
    "objectID": "talks/2017-05-25_overview-of-htmlwidgets/index.html#overview",
    "href": "talks/2017-05-25_overview-of-htmlwidgets/index.html#overview",
    "title": "An overview of htmlwidgets",
    "section": "Overview",
    "text": "Overview\nThe {htmlwidgets} package allows developers to create R bindings to JavaScript libraries. The resulting R packages allow the embedding of interactive content in R Markdown documents and Shiny web apps. There are over 50 available widgets. In this talk I give an overview of the htmlwidget framework and demonstrate the use of the {DT}, {leaflet} and {DiagrammeR} packages."
  },
  {
    "objectID": "talks/2017-05-25_overview-of-htmlwidgets/index.html#event-details",
    "href": "talks/2017-05-25_overview-of-htmlwidgets/index.html#event-details",
    "title": "An overview of htmlwidgets",
    "section": "Event details",
    "text": "Event details\nEvent: Warwick R User Group\nDate: May 25th, 2017\nTime: 17:00\nLocation: University of Warwick"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ella Kaye",
    "section": "",
    "text": "Hello and welcome!\n\n\n\n\n\nAbout me, my interests and experience, and my work as a Research Software Engineer.\n\n\nABOUT\n\n\n\n\n\n\n\n\nI sometimes write about what I’m doing and learning, mostly about  and building websites.\n\n\nPOSTS\n\n\n\n\n\n\n\n\nSlides and resources from talks I’ve given at R and RLadies user groups and conferences.\n\n\nTALKS\n\n\n\n\n\n\n\n\nI develop R packages. Here are links to their repos, websites and any other resources.\n\n\nPACKAGES\n\n\n\n\n\n\n\n\nI love the R community! Here’s how to get involved, and groups I help organise or contribute to.\n\n\nCOMMUNITY\n\n\n\n\n\n\n\n\nWhere to find me online and how to get in touch. I’d love to hear from you!\n\n\nCONTACT"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Ella Kaye",
    "section": "",
    "text": "I am a Research Software Engineer in the Department of Statistics at the University of Warwick, working with Dr Heather Turner on her fellowship “Sustainability and EDI (Equality, Diversity and Inclusion) in the R Project”.\nThis involves:\n👩‍💻 Contributing to the  project through code, infrastructure & outreach.\n📦 Contributing to packages on the Comprehensive R Archive Network (CRAN).\n🚀 Capacity-building in R and data science at the University of Warwick.\n💪 Community-building in the R and RSE communities with a focus on EDI.\nPlease see my professional webpage for more details, including links to my teaching resources.\n\nPreviously\nPrior to my current role, my academic path has taken me from a BA in Mathematics and Philosophy (University of Oxford), through an MA in History and Philosophy of Science and Technology (University of Toronto), an MPhil in Mathematics Education (University of Cambridge), an MSc in Applied Statistics (University of Oxford) and the OxWaSP programme for postgraduate research in Statistics (University of Warwick). I also have a PGCE in Secondary Mathematics, have taught at secondary school, and worked in market research.\n\n\n\nMy  journey\n\n2014: first R course as part of MSc in Applied Statistics\n2015: first taste of ggplot2\n2016: first R package\n2017: first community involvement (useR!2017, Oxford R User Group, rainbowR, @R_LGBTQ)\n2020: first TidyTuesday contribution\n2021: third time’s the charm building a website in R, using {distill}\n2022: as an RSE, I now get to be both an  enthusiast and professional.\n\nI love R! I have used it in extensively in my research as a statistician for visualising, analysing and modelling data. I have also used it for personal projects and writing packages. My enthusiasm for all things RMarkdown (especially {distill}) has now morphed into excitement about Quarto. I have particularly enjoyed using it to build this website (my fourth!) 1\nI love the R community!] I am a co-founder and co-organiser of RainbowR a community that supports, promotes and connects LGBTQ+ people who code in the R language. I am also on the Community team of R Forwards. I am on the organising committee of the Warwick R User Group and was previously co-organiser of the Oxford R User Group. Here’s more on the communities that I’m involved with, as well as lots of information about and links to groups that you may be interested in getting involved with.\nI enjoy sharing what I know/am learning about R with others, particularly by writing blog posts and speaking at R-Ladies and R User Group meetups. Here are some talks I’ve given. Please get in touch if you’d like me to speak at your group.\nI live in Oxford, UK, with my wife and our two young children.\n\n\n\n\n\nFootnotes\n\n\nPrevious versions were built with blogdown, then hugodown, then distill.↩︎"
  },
  {
    "objectID": "packages/distilltools/index.html#main-resources",
    "href": "packages/distilltools/index.html#main-resources",
    "title": "distilltools",
    "section": "Main resources",
    "text": "Main resources\n source  documentation  hex sticker"
  },
  {
    "objectID": "packages/distilltools/index.html#additional-resources",
    "href": "packages/distilltools/index.html#additional-resources",
    "title": "distilltools",
    "section": "Additional resources",
    "text": "Additional resources\ndistilltools: Creating a Curated, Collaborative Community Package\nA book chapter in The Future of Data Science from Data Science by Design, outlining the vision for {distilltools}\n book chapter\nA blog post about the {distilltools} function for modifying the default syntax highlighting scheme:\n blog post\nA blog post giving a sneak-peek at {distilltools}:\n blog post"
  },
  {
    "objectID": "packages/distilltools/index.html#overview",
    "href": "packages/distilltools/index.html#overview",
    "title": "distilltools",
    "section": "Overview",
    "text": "Overview\n{distilltools} is collection of tools to support the creation and styling of content on websites created using the distill package in R.\nIt is in the very early stages of development. I am actively seeking contributions - both ideas and code - to help build the package to be broadly useful to a wide variety of distill users. The idea is for the package to become a curated, collaborative, community-driven project. In terms of relationship between packages, I hope in time that distilltools can be for distill something like what xaringanExtra and xaringanthemer are for xaringan. Some of what I have in mind may sit better within the distill package itself, and I will be reaching out to the distill team about that.\n\nUpdate (2022-05-29)\nDevelopment on distilltools has been on a bit of a hiatus recently, but I will resume work on it. When I do, I want to ensure the package also has the functionality to support websites created in R with Quarto, and so I may also rename the package.\nAn article on distilltools, and my intentions for it, is featured in The Future of Sata Science anthology (written October 2021, published June 2022).\n\n\nInstallation\n\n# install.packages(\"remotes\")\n# requires remotes >= 2.2\nremotes::install_github(\"EllaKaye/distilltools\")\n\n# for remotes < 2.2\nremotes::install_github(\"EllaKaye/distilltools\", ref = \"main\")\n\n\n\nFunctionality\nThere are currently five exported functions in distilltools.\n\nBlogging functions\n\ncreate_post_from_template(): this function works almost identically to distill::create_post(), but extends it with an added path argument that specifies an .Rmd file to use as a template for the post. This function can also be run interactively using the Create post (from template) RStudio addin. See ?create_post_from_template and ?available_templates for details on using your R Markdown templates with the addin.\navailable_templates(): lists a named vector of available R Markdown templates for new posts, talks, etc.\ncreate_talk(): a wrapper around distill::create_post() that creates a post in the talk directory and includes buttons (made with icon-link()) for slides (both web and pdf), material, video and project. These can easily be edited in the resulting .Rmd file. This function was inspired by Eric Ekholm’s blog post.\n\n\n\nStyling functions\n\nicon_link(): creates the html for a link button with icon and text. Output of icon_link will need styling via the icon-link class to make it look like a button. For more details on this function, see this blog post from John Paul Helveston. For examples of styling the icon-link class, see John Paul Helveston’s css and Ella Kaye’s css.\nmodify_default_highlighting(): allows the user to swap the five colours used in {distill}’s default syntax highlighting scheme with five colours of their choice, and saves the resulting .theme file into the working directory.\n\n\n\n\nContributing to {distilltools}\nWe’re actively seeking contributions!\n\nDo you have a distill website? If so, what tools would you help you in the creation, upkeep and styling of your site? Let us know by with an issue.\nDo you have functions that you’ve written for your distill workflow? If they help you, they’ll almost certainly be helpful to others to. Consider submitting (generalized) versions of them for inclusion in distilltools!\n\nThere are lots of other ways to support and contribute to {distilltools}. Please see the contributing guide for more details.\n\n\nCode of conduct\nPlease note that the distilltools project is released with a contributor code of conduct. By contributing to this project, you agree to abide by its terms."
  },
  {
    "objectID": "packages/EMK/index.html#main-resources",
    "href": "packages/EMK/index.html#main-resources",
    "title": "EMK",
    "section": "Main resources",
    "text": "Main resources\n source  hex sticker"
  },
  {
    "objectID": "packages/EMK/index.html#additional-resources",
    "href": "packages/EMK/index.html#additional-resources",
    "title": "EMK",
    "section": "Additional resources",
    "text": "Additional resources\nA blog post about the inspiration for creating this package and the n_letter_words() function in it:\n blog post"
  },
  {
    "objectID": "packages/BradleyTerryScalable/index.html#main-resources",
    "href": "packages/BradleyTerryScalable/index.html#main-resources",
    "title": "BradleyTerryScalable",
    "section": "Main resources",
    "text": "Main resources\n source  documentation  hex sticker"
  },
  {
    "objectID": "packages/BradleyTerryScalable/index.html#additional-resources",
    "href": "packages/BradleyTerryScalable/index.html#additional-resources",
    "title": "BradleyTerryScalable",
    "section": "Additional resources",
    "text": "Additional resources\nAn overview of the BradleyTerryScalable package (2022):\n slides  materials\nA presentation introducing the BradleyTerryScalable package (2017):\n slides  materials"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Ella Kaye",
    "section": "",
    "text": "POSTS\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nCustom syntax highlighting for {distill} part 2\n\n\nCreating the palette\n\n\n\n\ndistill\n\n\ncolour\n\n\naccessibility\n\n\nR\n\n\n\n\nHow to create an appealing and accessible colour palette for a syntax highlighting scheme\n\n\n\n\n\n\nMay 26, 2021\n\n\nElla Kaye\n\n\n\n\n\n\n  \n\n\n\n\nCustom syntax highlighting for {distill} part 1\n\n\nModifying the default theme\n\n\n\n\ndistill\n\n\ndistilltools\n\n\ncolour\n\n\naccessibility\n\n\nR\n\n\n\n\nA guide to modifying the default {distill} syntax highlighting theme, including colour choice considerations, and its implementation in {distilltools}\n\n\n\n\n\n\nMay 25, 2021\n\n\nElla Kaye\n\n\n\n\n\n\n  \n\n\n\n\nWelcome to my {distill} website!\n\n\n\n\n\n\n\ndistill\n\n\ndistilltools\n\n\npackage development\n\n\nR\n\n\n\n\nResources and sites I found inspiring when building my new site, and a sneak-peek at {distilltools}, an exciting new project for {distill} users\n\n\n\n\n\n\nMay 8, 2021\n\n\nElla Kaye\n\n\n\n\n\n\n  \n\n\n\n\nAdvent of Code 2020\n\n\n\n\n\n\n\nR\n\n\nAdvent of Code\n\n\n\n\nMy attempts at Advent of Code, 2020\n\n\n\n\n\n\nDec 9, 2020\n\n\nElla Kaye\n\n\n\n\n\n\n  \n\n\n\n\nn_letter_words and a personal (publicly available) package\n\n\n\n\n\n\n\nR\n\n\npackage development\n\n\n\n\nHow I created a handy function and a personal package\n\n\n\n\n\n\nJun 17, 2017\n\n\nElla Kaye\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "packages.html",
    "href": "packages.html",
    "title": "Ella Kaye",
    "section": "",
    "text": "PACKAGES\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndistilltools\n\n\n{distilltools} is collection of tools to support the creation and styling of content on websites created using the {distill} package in R.\n\n\n\nElla Kaye, John Paul Helveston, Michael McCarthy\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEMK\n\n\nA collection of miscellaneous functions I have written that I personally find helpful in a variety of contexts.\n\n\n\nElla Kaye\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBradleyTerryScalable\n\n\n{BradleyTerryScalable} is an R package for fitting the Bradley-Terry model to pair-comparison data, to enable statistically principled ranking of a potentially large number…\n\n\n\nElla Kaye, David Firth\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html#previously",
    "href": "about.html#previously",
    "title": "Ella Kaye",
    "section": "Previously",
    "text": "Previously\nPrior to my current role, my academic path has taken me from a BA in Mathematics and Philosophy (University of Oxford), through an MA in History and Philosophy of Science and Technology (University of Toronto), an MPhil in Mathematics Education (University of Cambridge), an MSc in Applied Statistics (University of Oxford) and the OxWaSP programme for postgraduate research in Statistics (University of Warwick). I also have a PGCE in Secondary Mathematics, have taught at secondary school, and worked in market research."
  },
  {
    "objectID": "about.html#my-fa-brands-r-project-journey",
    "href": "about.html#my-fa-brands-r-project-journey",
    "title": "Ella Kaye",
    "section": "My  journey",
    "text": "My  journey\n\n2014: first R course as part of MSc in Applied Statistics\n2015: first taste of ggplot2\n2016: first R package\n2017: first community involvement (useR!2017, Oxford R User Group, rainbowR, @R_LGBTQ)\n2020: first TidyTuesday contribution\n2021: third time’s the charm building a website in R, using {distill}\n2022: as an RSE, I now get to be both an  enthusiast and professional.\n\nI love R! I have used it in extensively in my research as a statistician for visualising, analysing and modelling data. I have also used it for personal projects and writing packages. My enthusiasm for all things RMarkdown (especially {distill}) has now morphed into excitement about Quarto. I have particularly enjoyed using it to build this website (my fourth!) 1\nI love the R community!] I am a co-founder and co-organiser of RainbowR a community that supports, promotes and connects LGBTQ+ people who code in the R language. I am also on the Community team of R Forwards. I am on the organising committee of the Warwick R User Group and was previously co-organiser of the Oxford R User Group. Here’s more on the communities that I’m involved with, as well as lots of information about and links to groups that you may be interested in getting involved with.\nI enjoy sharing what I know/am learning about R with others, particularly by writing blog posts and speaking at R-Ladies and R User Group meetups. Here are some talks I’ve given. Please get in touch if you’d like me to speak at your group.\nI live in Oxford, UK, with my wife and our two young children."
  }
]